{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Langdrive's Documentation Portal Langdrive: Easily train and deploy your favorite models. There are many ways to train and develop LLMs with LangDrive - One way is to configure a YAML doc and by issuing a CLI command. Another way would be importing it as a class modules within a project of your own, YAML doc optional. Whether you're a beginner or an experienced developer, our Data Connectors and LLM tools empower you to build, integrate, and deploy with confidence. Data Connectors help source data from third parties (email, firebase, gdrive) and prepare it for your models. When it comes to training, hosting, and deploying models (Locally, Huggingface, SageMaker, CloudRun), our LLM tools have you covered. All of this is readily available from CLI arguements, a YAML doc, or directly in-code. LangDrive, built specifically for Node.js, makes training and deploying AI models effortless. We provide a library that facilitates data connection and automates training and deployment, ensuring your projects are easy to manage and scale. Read our Getting Started page to jump right in or browse our documentation using the nav below. Data Connectors Overview Get to grips with classes that help you fetch and process data. This includes Firestore for database interactions, Google Drive for file management, and EmailRetriever for fetching emails. Google Drive This section provides a comprehensive look at its constructor, various methods, and how it leverages Google APIs for file operations and authentication. Explore how DriveUtils enhances your Google Drive experience with functionalities covering file listing, information retrieval, and file management. Firestore Designed for robust interaction with Firebase Firestore, learn about its constructor, key methods, and how it can enhance your database interactions. EmailRetriever Tailored for retrieving emails from different email clients using SMTP configurations, discover its constructor, key methods, and additional features. LLM Overview Training and deploying LLMs require resources most of us do not have. That is where our HuggingFace , HerokuHandler , and utils class come into play. These set of classes fascilitate the training and deployment of your LLM. HuggingFace Explore the HuggingFace class, your gateway to interacting with the Hugging Face API. Learn about its constructor, key methods, and how it can simplify your AI-driven tasks. HerokuHandler Understand the HerokuHandler class, which simplifies interactions with the Heroku API. This overview covers its constructor, key methods, and how it can enhance your Heroku experience. Chatbot Discover the DriveChatbot , a demonstration and testing tool for Async Promises in chatbot interactions. Google OAuth2 keys are required to run your own instance. Read our tutorial on OAuth2 on our blog . Utils Understand the essential Node.js script for deploying machine learning models, including its main functions, modules, and how it utilizes various libraries for file operations and environment management. Includes CLI utils. Training This section covers its constructor, key methods, and how it streamlines the training process of your models. Contributing Interested in contributing to LangDrive? Check out our contributing guide . Navigate through our sections to find comprehensive guides and insights that suit your development needs!","title":"Home"},{"location":"#welcome-to-langdrives-documentation-portal","text":"Langdrive: Easily train and deploy your favorite models. There are many ways to train and develop LLMs with LangDrive - One way is to configure a YAML doc and by issuing a CLI command. Another way would be importing it as a class modules within a project of your own, YAML doc optional. Whether you're a beginner or an experienced developer, our Data Connectors and LLM tools empower you to build, integrate, and deploy with confidence. Data Connectors help source data from third parties (email, firebase, gdrive) and prepare it for your models. When it comes to training, hosting, and deploying models (Locally, Huggingface, SageMaker, CloudRun), our LLM tools have you covered. All of this is readily available from CLI arguements, a YAML doc, or directly in-code. LangDrive, built specifically for Node.js, makes training and deploying AI models effortless. We provide a library that facilitates data connection and automates training and deployment, ensuring your projects are easy to manage and scale. Read our Getting Started page to jump right in or browse our documentation using the nav below.","title":"Welcome to Langdrive's Documentation Portal"},{"location":"#data-connectors-overview","text":"Get to grips with classes that help you fetch and process data. This includes Firestore for database interactions, Google Drive for file management, and EmailRetriever for fetching emails.","title":"Data Connectors Overview"},{"location":"#google-drive","text":"This section provides a comprehensive look at its constructor, various methods, and how it leverages Google APIs for file operations and authentication. Explore how DriveUtils enhances your Google Drive experience with functionalities covering file listing, information retrieval, and file management.","title":"Google Drive"},{"location":"#firestore","text":"Designed for robust interaction with Firebase Firestore, learn about its constructor, key methods, and how it can enhance your database interactions.","title":"Firestore"},{"location":"#emailretriever","text":"Tailored for retrieving emails from different email clients using SMTP configurations, discover its constructor, key methods, and additional features.","title":"EmailRetriever"},{"location":"#llm-overview","text":"Training and deploying LLMs require resources most of us do not have. That is where our HuggingFace , HerokuHandler , and utils class come into play. These set of classes fascilitate the training and deployment of your LLM.","title":"LLM Overview"},{"location":"#huggingface","text":"Explore the HuggingFace class, your gateway to interacting with the Hugging Face API. Learn about its constructor, key methods, and how it can simplify your AI-driven tasks.","title":"HuggingFace"},{"location":"#herokuhandler","text":"Understand the HerokuHandler class, which simplifies interactions with the Heroku API. This overview covers its constructor, key methods, and how it can enhance your Heroku experience.","title":"HerokuHandler"},{"location":"#chatbot","text":"Discover the DriveChatbot , a demonstration and testing tool for Async Promises in chatbot interactions. Google OAuth2 keys are required to run your own instance. Read our tutorial on OAuth2 on our blog .","title":"Chatbot"},{"location":"#utils","text":"Understand the essential Node.js script for deploying machine learning models, including its main functions, modules, and how it utilizes various libraries for file operations and environment management. Includes CLI utils.","title":"Utils"},{"location":"#training","text":"This section covers its constructor, key methods, and how it streamlines the training process of your models.","title":"Training"},{"location":"#contributing","text":"Interested in contributing to LangDrive? Check out our contributing guide . Navigate through our sections to find comprehensive guides and insights that suit your development needs!","title":"Contributing"},{"location":"cli/","text":"Command Line Interface Simply: Install Langdrive: npm isntall langdrive Train a model: `langdrive deploy` + [...Args]` Here are your Args: --path - Path to a YAML file. --csv - Path to a CSV to train on. --model - Name of model to use. --hfkey - API key of Huggingface --deploy - Boolean: True/False. CLI args are parsed as YAML when running commands. this is a non-exhaustive list of valid operations langdrive deploy langdrive deploy yaml=../pathToYaml.yaml langdrive deploy hfAPIKey=1234 path=../shared.csv langdrive deploy hfAPIKey=1234 path=../shared.csv inputValue=colname outputValue=colname langdrive deploy hfAPIKey=1234 inputPath=../input.csv inputValue=colname outputPath=../output.csv outputValue=colname","title":"CLI"},{"location":"cli/#command-line-interface","text":"Simply: Install Langdrive: npm isntall langdrive Train a model: `langdrive deploy` + [...Args]` Here are your Args: --path - Path to a YAML file. --csv - Path to a CSV to train on. --model - Name of model to use. --hfkey - API key of Huggingface --deploy - Boolean: True/False. CLI args are parsed as YAML when running commands. this is a non-exhaustive list of valid operations langdrive deploy langdrive deploy yaml=../pathToYaml.yaml langdrive deploy hfAPIKey=1234 path=../shared.csv langdrive deploy hfAPIKey=1234 path=../shared.csv inputValue=colname outputValue=colname langdrive deploy hfAPIKey=1234 inputPath=../input.csv inputValue=colname outputPath=../output.csv outputValue=colname","title":"Command Line Interface"},{"location":"contributors/","text":"Contributing Thank you for the interest! We would love to see a PR! At the moment the CLI only supports the deploy command: main.js #!/usr/bin/env node if (process.argv.length >= 3 && process.argv[2] === 'deploy') { console.log('test'); } To help with your development, these command may help: npm link --loglevel verbose - Uses loads the current repo and a npm module. npm unlink langdrive - Unlink for good measure npm unlink langdrive, npm link --loglevel verbose - Do both langdrive deploy --path \"../../path/to/file.yaml\" - Test path","title":"Contributors"},{"location":"contributors/#contributing","text":"Thank you for the interest! We would love to see a PR! At the moment the CLI only supports the deploy command: main.js #!/usr/bin/env node if (process.argv.length >= 3 && process.argv[2] === 'deploy') { console.log('test'); } To help with your development, these command may help: npm link --loglevel verbose - Uses loads the current repo and a npm module. npm unlink langdrive - Unlink for good measure npm unlink langdrive, npm link --loglevel verbose - Do both langdrive deploy --path \"../../path/to/file.yaml\" - Test path","title":"Contributing"},{"location":"demo/","text":"Demo Create a chatbot using Google Drive. Make it smart and store data by connecting it to you or your visitors' google drive account. Select your AI Model and optionally connect you and/or your users' google drive. 1 CLICK DEPLOY Get a chatbot up and running NOW ! Click here to Set Heroku Secret Variables to gain access to their service GOOGLE_WEB_CLIENT_ID and GOOGLE_WEB_CLIENT_SECRET with Google OAuth2 Keys instructions are needed for user login and to connect Google Drive to their chatbot. OPENAI_API_KEY for ChatGPT4. HUGGINGFACE_API_KEY to use a HuggingFace LLM. App Developers You can clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start More instructions for hands-on configuration available in the Chatbot section","title":"Demo"},{"location":"demo/#demo","text":"Create a chatbot using Google Drive. Make it smart and store data by connecting it to you or your visitors' google drive account. Select your AI Model and optionally connect you and/or your users' google drive.","title":"Demo"},{"location":"demo/#1-click-deploy","text":"Get a chatbot up and running NOW ! Click here to Set Heroku Secret Variables to gain access to their service GOOGLE_WEB_CLIENT_ID and GOOGLE_WEB_CLIENT_SECRET with Google OAuth2 Keys instructions are needed for user login and to connect Google Drive to their chatbot. OPENAI_API_KEY for ChatGPT4. HUGGINGFACE_API_KEY to use a HuggingFace LLM.","title":"1 CLICK DEPLOY"},{"location":"demo/#app-developers","text":"You can clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start More instructions for hands-on configuration available in the Chatbot section","title":"App Developers"},{"location":"gettingStarted/","text":"Getting Started Thank you for taking interest in LangDrive! Langdrive's set of connectors and services makes training LLMs easy for downstream applications, and you can get started with just a CSV file. By providing a huggingface API key you can train models and even host them in the cloud \ud83d\ude09 Import langdrive in your next project or configure and execute Langdrive directly from the CLI. The remainder of this article will explore using both approaches for training and deploy models with langdrive. Along the way we will explore the use of a YAML doc to help with the connecting to data and services. Using the CLI Node developers can train and deploy a model in 2 simple steps. npm install langDrive langdrive train --csv ./path/to/csvFileName.csv --hftoken apikey123 --deploy In this case, Langdrive will retrieve the data, train a model, host it's weights on huggingface, and return an inference endpoint you may use to query the LLM. The command langdrive train is used to train the LLM, please see how to configure the command below. args: yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training dataCSV*The training data should be a two-column CSV of input and output pairs. hftoken : Explain what its baseModel : The original model to train: This can be one of the models in our supported models [list the supported models] deployToHf : true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model It is assumed you do not want to deploy your model if you run langdrive train . In such a case a link to where you can download the weights will be provided. Adding --deploy will return a link to the inferencing endpoint. Read more how to ingest simple data using the CLI from the CLI docs. For more comlex examples, read on... Getting Started with YAML Getting the data and services you need shouldn't be the hardest part about training your models! Using YAML, you can configure more advanced data retrieval and training/ deployment strategies. Once configured, these settings are available for the standalone API and also from the CLI when using YAML. Refer to the Yaml docs for more information or read on... Step 1: Configure your data connectors Our growing list of data-connectors allow anyone to retrieve data through a simple config doc. As LangDrive grows, our set of Open-Source integrations will grow. At the moment, you can connect to your data using our email , firestore , and gdrive classes. In essense, config of these data-connectors is as straight forward as: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: clientJson: \"secrets/drive_service_client.json\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL You may specify .env variables using env: as a prefix for your secret information. Once this information is provided, the entire OAuth Process will automatically be handled on your behalf when using any associated library, regardless if it's used in the CLI or API. Please refer to our notes on security for more information on the Outh2 process when using google. Step 2: Configure your llm tools Once you have your data-connectors set up, config your training and deployment information. The last step will be to connect the two. Training on huggingface and hosting the weights on huggingface hubs: huggingface: token: env:HUGGINGFACE_API_KEY deployTrainedModel: false NOTE : To specify the model you want to train and where to host it: huggingface: token: env:HUGGINGFACE_API_KEY baseModel: name: \"vilsonrodrigues/falcon-7b-instruct-sharded\" trainedModel: name: \"karpathic/falcon-7b-instruct-tuned\" deployTrainedModel: true Simple enough, huh? Here comes the final step. Connecting your data to your llm To connect data to your llm tool, we will need to create a new YAML entry train: . Here we specify specific the specific data we want to train on. In the case of a CSV, a most simple example, we can use the path value to specify it's location. langdrive.yaml train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Now lets show how to query data from one of those third-party services we configured earlier. Within the train entry, setting a service and query will do the trick. Set a data-connector as the service and one one of it's methods / arg values as the query value. This will require exploring class documentation. langdrive.yaml train: service: 'firebase' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 If the file has two columns they are assumed to be in the order [input, output]. If more columns exist, langdrive grabs the first two columns after first looking for an 'inputValue' and 'outpuValue' column. The same logic applies for information retrieved from a query and works similarly for nested Json Objects (ala: att1.attr2 ) Gettings Started with API: Our classes can be exposed in the typical manner. For more information on any one class, please refer to it's corresponding documentation. Coming Soon: Deploy self-hosted cloud based training infrastructure on google, heroku, or huggingface. Code is currently being used internally and is under development prior to general release - code avaialbe in repo under /src/train . If you would like to interact directly directly with our training endpoint you can call our hosted training image directly via the langdrive API. Endpoint: POST https://api.langdrive.ai/train Request Body: The request accepts the following data in JSON format. { \"baseModel\": \"string\", \"hfToken\": \"string\", \"deployToHf\": \"Boolean\", \"trainingData\": \"Array\", \"hfModelPath\": \"string\", } baseModel : The original model to train. This can be a hugging face model or one of the list of models that we support Type: String Required: Yes hfToken : Your hugging face token with write permissions. You can create a hugging face access token here Type: String Required: Yes deployToHf : A boolean representing whether or not to deploy the model to hugging face after training Type: Boolean Required: Yes trainingData : This is an array of objects. Each object must have two attributes: input and output. The input attribute represents the user\u2019s input and output attribute represents the model\u2019s output. Type: Array Required: Yes hfModelPath : The hugging face model repository to deploy the model to after training is complete Type: String Required: No HTTP/1.1 200 Content-type: application/json { \"success\": \"true\", } Model Training We plan to expand the number of available models for training. at the mopemnt only sharded models work as using PEFT is how these models are trained. Models Support Matrix Causal Language Modeling Model Supported Falcon-7b-sharded \u2705 GPT-2 Comming Soon Bloom Comming Soon OPT Comming Soon LLaMA Comming Soon ChatGLM Comming Soon Model Type Support Model Type Support Conditional Generation \u2705 Conditional Generation \u2705 Sequence Classification \u2705 Token Classification \u2705 Text-to-Image Generation Image Classification Image to text (Multi-modal models) Semantic Segmentation","title":"Getting Started"},{"location":"gettingStarted/#getting-started","text":"Thank you for taking interest in LangDrive! Langdrive's set of connectors and services makes training LLMs easy for downstream applications, and you can get started with just a CSV file. By providing a huggingface API key you can train models and even host them in the cloud \ud83d\ude09 Import langdrive in your next project or configure and execute Langdrive directly from the CLI. The remainder of this article will explore using both approaches for training and deploy models with langdrive. Along the way we will explore the use of a YAML doc to help with the connecting to data and services.","title":"Getting Started"},{"location":"gettingStarted/#using-the-cli","text":"Node developers can train and deploy a model in 2 simple steps. npm install langDrive langdrive train --csv ./path/to/csvFileName.csv --hftoken apikey123 --deploy In this case, Langdrive will retrieve the data, train a model, host it's weights on huggingface, and return an inference endpoint you may use to query the LLM. The command langdrive train is used to train the LLM, please see how to configure the command below. args: yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training dataCSV*The training data should be a two-column CSV of input and output pairs. hftoken : Explain what its baseModel : The original model to train: This can be one of the models in our supported models [list the supported models] deployToHf : true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model It is assumed you do not want to deploy your model if you run langdrive train . In such a case a link to where you can download the weights will be provided. Adding --deploy will return a link to the inferencing endpoint. Read more how to ingest simple data using the CLI from the CLI docs. For more comlex examples, read on...","title":"Using the CLI"},{"location":"gettingStarted/#getting-started-with-yaml","text":"Getting the data and services you need shouldn't be the hardest part about training your models! Using YAML, you can configure more advanced data retrieval and training/ deployment strategies. Once configured, these settings are available for the standalone API and also from the CLI when using YAML. Refer to the Yaml docs for more information or read on...","title":"Getting Started with YAML"},{"location":"gettingStarted/#step-1-configure-your-data-connectors","text":"Our growing list of data-connectors allow anyone to retrieve data through a simple config doc. As LangDrive grows, our set of Open-Source integrations will grow. At the moment, you can connect to your data using our email , firestore , and gdrive classes. In essense, config of these data-connectors is as straight forward as: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: clientJson: \"secrets/drive_service_client.json\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL You may specify .env variables using env: as a prefix for your secret information. Once this information is provided, the entire OAuth Process will automatically be handled on your behalf when using any associated library, regardless if it's used in the CLI or API. Please refer to our notes on security for more information on the Outh2 process when using google.","title":"Step 1: Configure your data connectors"},{"location":"gettingStarted/#step-2-configure-your-llm-tools","text":"Once you have your data-connectors set up, config your training and deployment information. The last step will be to connect the two. Training on huggingface and hosting the weights on huggingface hubs: huggingface: token: env:HUGGINGFACE_API_KEY deployTrainedModel: false NOTE : To specify the model you want to train and where to host it: huggingface: token: env:HUGGINGFACE_API_KEY baseModel: name: \"vilsonrodrigues/falcon-7b-instruct-sharded\" trainedModel: name: \"karpathic/falcon-7b-instruct-tuned\" deployTrainedModel: true Simple enough, huh? Here comes the final step.","title":"Step 2: Configure your llm tools"},{"location":"gettingStarted/#connecting-your-data-to-your-llm","text":"To connect data to your llm tool, we will need to create a new YAML entry train: . Here we specify specific the specific data we want to train on. In the case of a CSV, a most simple example, we can use the path value to specify it's location. langdrive.yaml train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Now lets show how to query data from one of those third-party services we configured earlier. Within the train entry, setting a service and query will do the trick. Set a data-connector as the service and one one of it's methods / arg values as the query value. This will require exploring class documentation. langdrive.yaml train: service: 'firebase' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 If the file has two columns they are assumed to be in the order [input, output]. If more columns exist, langdrive grabs the first two columns after first looking for an 'inputValue' and 'outpuValue' column. The same logic applies for information retrieved from a query and works similarly for nested Json Objects (ala: att1.attr2 )","title":"Connecting your data to your llm"},{"location":"gettingStarted/#gettings-started-with-api","text":"Our classes can be exposed in the typical manner. For more information on any one class, please refer to it's corresponding documentation. Coming Soon: Deploy self-hosted cloud based training infrastructure on google, heroku, or huggingface. Code is currently being used internally and is under development prior to general release - code avaialbe in repo under /src/train . If you would like to interact directly directly with our training endpoint you can call our hosted training image directly via the langdrive API. Endpoint: POST https://api.langdrive.ai/train Request Body: The request accepts the following data in JSON format. { \"baseModel\": \"string\", \"hfToken\": \"string\", \"deployToHf\": \"Boolean\", \"trainingData\": \"Array\", \"hfModelPath\": \"string\", } baseModel : The original model to train. This can be a hugging face model or one of the list of models that we support Type: String Required: Yes hfToken : Your hugging face token with write permissions. You can create a hugging face access token here Type: String Required: Yes deployToHf : A boolean representing whether or not to deploy the model to hugging face after training Type: Boolean Required: Yes trainingData : This is an array of objects. Each object must have two attributes: input and output. The input attribute represents the user\u2019s input and output attribute represents the model\u2019s output. Type: Array Required: Yes hfModelPath : The hugging face model repository to deploy the model to after training is complete Type: String Required: No HTTP/1.1 200 Content-type: application/json { \"success\": \"true\", }","title":"Gettings Started with API:"},{"location":"gettingStarted/#model-training","text":"We plan to expand the number of available models for training. at the mopemnt only sharded models work as using PEFT is how these models are trained.","title":"Model Training"},{"location":"gettingStarted/#models-support-matrix","text":"","title":"Models Support Matrix"},{"location":"gettingStarted/#causal-language-modeling","text":"Model Supported Falcon-7b-sharded \u2705 GPT-2 Comming Soon Bloom Comming Soon OPT Comming Soon LLaMA Comming Soon ChatGLM Comming Soon","title":"Causal Language Modeling"},{"location":"gettingStarted/#model-type-support","text":"Model Type Support Conditional Generation \u2705 Conditional Generation \u2705 Sequence Classification \u2705 Token Classification \u2705 Text-to-Image Generation Image Classification Image to text (Multi-modal models) Semantic Segmentation","title":"Model Type Support"},{"location":"yaml/","text":"There are many ways to configure your YAML doc to support maximal flexibility. The basis of your YAML doc will most typically have a train object along with any other classes you want to configure The Classes being configured like: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: clientJson: \"secrets/drive_service_client.json\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL huggingface: token: env:HUGGINGFACE_API_KEY note : CLI based commands will retrieve the YAML doc and merge any args into the root of the yaml doc and processed accordingly. Example 0: Bespoke example with many settings ``` verbose: true firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: clientJson: \"secrets/drive_service_client.json\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL huggingface: token: env:HUGGINGFACE_API_KEY baseModel: name: \"vilsonrodrigues/falcon-7b-instruct-sharded\" trainedModel: name: \"karpathic/falcon-7b-instruct-tuned\" deployTrainedModel: true train: service: firestore query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [\"type\"] filterData: [\"customer-inquiry-bot\"] operation: [\"==\"] limit: 5 input: value: \"chat.0.content\" output: value: \"chat.1.content\" ``` Example 1: Training on a CSV with two columns (or an input and output column). train: path: ../shared.csv Example 2: Specify Input and Output values in a CSV train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Example 3: Attribute to extract from path train: inputPath: ../input.csv outputPath: ../output.csv inputValue: input outpuValue: output Example 4: Attribute to extraxt path using input and output objects train: input: path: ../input.csv value: colname output: path: ../output.csv value: colname Example 5: Specifying default path for Input and Output train: path: ../shared.csv input: value: colname output: value: colname Querying for data from a service is denoted by the query attribute placed. This may be placed as a base object, or nested within a 'input' or 'output' object. The query value follows the schema train: service: 'serviceName' query: serviceMethodName : {methodParameters} Here's an example: train: service: 'firebase' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 To specify the model you want to train and where to host it: huggingface: token: env:HUGGINGFACE_API_KEY baseModel: name: \"vilsonrodrigues/falcon-7b-instruct-sharded\" trainedModel: name: \"karpathic/falcon-7b-instruct-tuned\" deployTrainedModel: true","title":"Yaml"},{"location":"api/chatbot/","text":"NPM: Langdrive: DriveChatbot Class The Chatbot returns Async Promises. Chatbot's minimal initalization is like so: chatbot = new langdrive.DriveChatbot({model_config:{HuggingFaceAPIKey:<KEY>}}) or like so: chatbot = new langdrive.Chatbot({model_config:{openAIApiKey:<KEY>}}) Chatbot Example Script Get started with a sample script by created the following files: npm install langdrive dotenv node test.js .env File: OPENAI_API_KEY=<YOUR_KEY_HERE> GOOGLE_DESKTOP_CLIENT_KEYFILE_PATH=<YOUR_KEY_HERE> test.js File: require(\"dotenv\").config(); const langdrive = require(\"langdrive\"); // LangDrive returns promises (async()=>{ // To initialize Langdrive, give it a model to use and any associated config information. // Here we select openAi and pass it an API key (hidden behind .env) let chatbot = await new langdrive.DriveChatbot({ verbose: true, drive: { verbose: false, ...(!GOOGLE_DESKTOP_KEYFILE_PATH ? {} : { server: { embed_from_folder: \"chatbot\", embed_to_folder: \"chatbot/embeddings\", scopes: [\"https://www.googleapis.com/auth/drive\"], // serviceKeyFile: __dirname + \"/../\" + GOOGLE_SERVICE_KEYFILE_PATH // OR desktopKeyFile: __dirname + GOOGLE_DESKTOP_KEYFILE_PATH // ( Alternately:) desktopKeyFileContents: GOOGLE_DESKTOP_CLIENT_KEYFILE_CONTENTS // OR // desktopTokenFile: GOOGLE_DESKTOP_CLIENT_TOKEN_PATH: // ( Alternately:) desktopTokenFileContents: GOOGLE_DESKTOP_CLIENT_TOKEN_CONTENTS // OR //client_id: GOOGLE_DESKTOP_CLIENT_ID, // and //client_secret: GOOGLE_SERVICE_CLIENT_SECRET //and //client_redirect_uri: xyz } }) }, model: { service: !!HUGGINGFACE_API_KEY ? \"huggingFace\" : \"chatOpenAi\", model_config: !!HUGGINGFACE_API_KEY ? { model_id: \"meta-llama/Llama-2-30b\", huggingFaceApiKey: HUGGINGFACE_API_KEY } : { modelName: \"gpt-3.5-turbo\", // default = \"text-davinci-003\" // maxTokens: 256, // default = 256 openAIApiKey: OPENAI_API_KEY, temperature: 0.9 } }, agent: { type: \"chat-conversational-react-description\", memory_length: 2, vector_length: 2, verbose: false, tools: [], agent_config: {} // prefix // suffix } }); // LangDrive returns a promise, so let's await those. let prompt = \"My name is Michael, What can you do for me.\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What can you do for me in google drive?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What is my name?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); })() You can also clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start Chatbot Properties The props used in DriveChatbot( props ) configure your chatbot. Available settings and their default values are shown below.","title":"Chatbot"},{"location":"api/chatbot/#npm-langdrive-drivechatbot-class","text":"The Chatbot returns Async Promises. Chatbot's minimal initalization is like so: chatbot = new langdrive.DriveChatbot({model_config:{HuggingFaceAPIKey:<KEY>}}) or like so: chatbot = new langdrive.Chatbot({model_config:{openAIApiKey:<KEY>}})","title":"NPM: Langdrive: DriveChatbot Class"},{"location":"api/chatbot/#chatbot-example-script","text":"Get started with a sample script by created the following files: npm install langdrive dotenv node test.js .env File: OPENAI_API_KEY=<YOUR_KEY_HERE> GOOGLE_DESKTOP_CLIENT_KEYFILE_PATH=<YOUR_KEY_HERE> test.js File: require(\"dotenv\").config(); const langdrive = require(\"langdrive\"); // LangDrive returns promises (async()=>{ // To initialize Langdrive, give it a model to use and any associated config information. // Here we select openAi and pass it an API key (hidden behind .env) let chatbot = await new langdrive.DriveChatbot({ verbose: true, drive: { verbose: false, ...(!GOOGLE_DESKTOP_KEYFILE_PATH ? {} : { server: { embed_from_folder: \"chatbot\", embed_to_folder: \"chatbot/embeddings\", scopes: [\"https://www.googleapis.com/auth/drive\"], // serviceKeyFile: __dirname + \"/../\" + GOOGLE_SERVICE_KEYFILE_PATH // OR desktopKeyFile: __dirname + GOOGLE_DESKTOP_KEYFILE_PATH // ( Alternately:) desktopKeyFileContents: GOOGLE_DESKTOP_CLIENT_KEYFILE_CONTENTS // OR // desktopTokenFile: GOOGLE_DESKTOP_CLIENT_TOKEN_PATH: // ( Alternately:) desktopTokenFileContents: GOOGLE_DESKTOP_CLIENT_TOKEN_CONTENTS // OR //client_id: GOOGLE_DESKTOP_CLIENT_ID, // and //client_secret: GOOGLE_SERVICE_CLIENT_SECRET //and //client_redirect_uri: xyz } }) }, model: { service: !!HUGGINGFACE_API_KEY ? \"huggingFace\" : \"chatOpenAi\", model_config: !!HUGGINGFACE_API_KEY ? { model_id: \"meta-llama/Llama-2-30b\", huggingFaceApiKey: HUGGINGFACE_API_KEY } : { modelName: \"gpt-3.5-turbo\", // default = \"text-davinci-003\" // maxTokens: 256, // default = 256 openAIApiKey: OPENAI_API_KEY, temperature: 0.9 } }, agent: { type: \"chat-conversational-react-description\", memory_length: 2, vector_length: 2, verbose: false, tools: [], agent_config: {} // prefix // suffix } }); // LangDrive returns a promise, so let's await those. let prompt = \"My name is Michael, What can you do for me.\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What can you do for me in google drive?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What is my name?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); })() You can also clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start","title":"Chatbot Example Script"},{"location":"api/chatbot/#chatbot-properties","text":"The props used in DriveChatbot( props ) configure your chatbot. Available settings and their default values are shown below.","title":"Chatbot Properties"},{"location":"api/dataOverview/","text":"Data Connectors Overview Welcome to the Data Connectors Overview! This document offers a detailed guide on the functionalities and capabilities of several Node.js classes, designed to enhance your development experience. Firestore Class Overview Class: Firestore The Firestore class in Node.js is designed for robust interaction with Firebase Firestore. It supports various operations like querying, adding, updating, and deleting documents in your Firestore database. Constructor Parameters : props (Object): Contains the Firestore database instance. Description : Initializes the Firestore class with a database instance. Key Methods filterCollectionWithWhereClause(...) : Filters a collection using a where clause. addDocumentToCollection(...) : Adds a new document to a specified collection. updateDocument(...) : Updates an existing document in a collection. deleteDocumentFromCollection(...) : Deletes a document from a collection. getAllDocumentsInCollection(...) : Retrieves all documents from a specified collection. EmailRetriever Class Overview Class: EmailRetriever The EmailRetriever class in Node.js is tailored for retrieving emails from different email clients using SMTP configurations. It provides a streamlined approach to email retrieval. Constructor Parameters : emailAddress (String): The email account's address. emailPassword (String): The email account's password. emailClient (String): The email client hosting the account. verbose (Boolean): Enables verbose error logging. Description : Initializes the EmailRetriever with email credentials and client. Key Methods getEmailsInFolder(...) : Retrieves emails from a specific folder in the email account. validateSMTPConfig() : Validates the SMTP configuration for the email client. Additional Information SMTP Configuration : Uses predefined SMTP settings for supported email clients. Error Handling : Robust error management, especially for unsupported email clients. External API Integration : Utilizes external APIs for email retrieval. DriveUtils Class: DriveUtils The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs. Constructor Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web). Key Methods getDrive() : Initializes and retrieves the Google Drive instance. listFiles(props) : Lists files in Google Drive based on properties like directory, mime type, etc. listDirectories(props) : Lists all directories or directories within a specific directory. getFileInfo(props) : Retrieves information about a specific file based on provided criteria. getFileById(props) : Retrieves a file by its ID. getFileByName(props) : Retrieves a file by its name. createFile(props) : Creates a file in Google Drive. createAndOrGetContent(props) : Creates or retrieves content based on a given path and other criteria. updateFile(props) : Updates a file in Google Drive. Static Methods getAuthUrl(config) : Generates a Google authentication URL for obtaining access tokens. handleAuthCallback(config) : Handles the authentication callback from Google to get access tokens. checkAndRefresh(config) : Checks and refreshes the access token if it is expired. refreshToken(config) : Refreshes the access token. Comments and Additional Information The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to","title":"Overview"},{"location":"api/dataOverview/#data-connectors-overview","text":"Welcome to the Data Connectors Overview! This document offers a detailed guide on the functionalities and capabilities of several Node.js classes, designed to enhance your development experience.","title":"Data Connectors Overview"},{"location":"api/dataOverview/#firestore-class-overview","text":"","title":"Firestore Class Overview"},{"location":"api/dataOverview/#class-firestore","text":"The Firestore class in Node.js is designed for robust interaction with Firebase Firestore. It supports various operations like querying, adding, updating, and deleting documents in your Firestore database.","title":"Class: Firestore"},{"location":"api/dataOverview/#constructor","text":"Parameters : props (Object): Contains the Firestore database instance. Description : Initializes the Firestore class with a database instance.","title":"Constructor"},{"location":"api/dataOverview/#key-methods","text":"filterCollectionWithWhereClause(...) : Filters a collection using a where clause. addDocumentToCollection(...) : Adds a new document to a specified collection. updateDocument(...) : Updates an existing document in a collection. deleteDocumentFromCollection(...) : Deletes a document from a collection. getAllDocumentsInCollection(...) : Retrieves all documents from a specified collection.","title":"Key Methods"},{"location":"api/dataOverview/#emailretriever-class-overview","text":"","title":"EmailRetriever Class Overview"},{"location":"api/dataOverview/#class-emailretriever","text":"The EmailRetriever class in Node.js is tailored for retrieving emails from different email clients using SMTP configurations. It provides a streamlined approach to email retrieval.","title":"Class: EmailRetriever"},{"location":"api/dataOverview/#constructor_1","text":"Parameters : emailAddress (String): The email account's address. emailPassword (String): The email account's password. emailClient (String): The email client hosting the account. verbose (Boolean): Enables verbose error logging. Description : Initializes the EmailRetriever with email credentials and client.","title":"Constructor"},{"location":"api/dataOverview/#key-methods_1","text":"getEmailsInFolder(...) : Retrieves emails from a specific folder in the email account. validateSMTPConfig() : Validates the SMTP configuration for the email client.","title":"Key Methods"},{"location":"api/dataOverview/#additional-information","text":"SMTP Configuration : Uses predefined SMTP settings for supported email clients. Error Handling : Robust error management, especially for unsupported email clients. External API Integration : Utilizes external APIs for email retrieval.","title":"Additional Information"},{"location":"api/dataOverview/#driveutils","text":"","title":"DriveUtils"},{"location":"api/dataOverview/#class-driveutils","text":"The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs.","title":"Class: DriveUtils"},{"location":"api/dataOverview/#constructor_2","text":"Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web).","title":"Constructor"},{"location":"api/dataOverview/#key-methods_2","text":"getDrive() : Initializes and retrieves the Google Drive instance. listFiles(props) : Lists files in Google Drive based on properties like directory, mime type, etc. listDirectories(props) : Lists all directories or directories within a specific directory. getFileInfo(props) : Retrieves information about a specific file based on provided criteria. getFileById(props) : Retrieves a file by its ID. getFileByName(props) : Retrieves a file by its name. createFile(props) : Creates a file in Google Drive. createAndOrGetContent(props) : Creates or retrieves content based on a given path and other criteria. updateFile(props) : Updates a file in Google Drive.","title":"Key Methods"},{"location":"api/dataOverview/#static-methods","text":"getAuthUrl(config) : Generates a Google authentication URL for obtaining access tokens. handleAuthCallback(config) : Handles the authentication callback from Google to get access tokens. checkAndRefresh(config) : Checks and refreshes the access token if it is expired. refreshToken(config) : Refreshes the access token.","title":"Static Methods"},{"location":"api/dataOverview/#comments-and-additional-information","text":"The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to","title":"Comments and Additional Information"},{"location":"api/email/","text":"Email The EmailRetriever class in Node.js is designed to retrieve emails from different email clients using SMTP configurations. Class: EmailRetriever Constructor Parameters : emailAddress (String): The email address of the account. emailPassword (String): The password of the account. emailClient (String): The email client hosting the email address (e.g., \"gmail\", \"outlook\"). verbose (Boolean): Optional flag for verbose error logging. Description : Initializes the EmailRetriever with the provided email address, password, and client. Validates and sets the SMTP configuration based on the email client. Method: getEmailsInFolder(folderName, limit, IMAPSearchCommand) Parameters : folderName (String): The name of the folder to scan in the email account. limit (String): Maximum number of emails to retrieve. IMAPSearchCommand (String): The IMAP search command (e.g., \"ALL\", \"UNSEEN\", \"SEEN\"). Returns : Array of emails or undefined. Description : Retrieves emails from a specific folder in the user's email account. Utilizes an external API for email retrieval. Handles and reports errors, especially if verbose is enabled. Additional Information SMTP Configuration Constants : The class uses predefined SMTP configurations for supported email clients, which are stored in emailClientSMTPConfigs . Error Handling : The class throws an error if the specified email client is not supported. External API Usage : Email retrieval is performed through a call to a specified external API ( EMAIL_RETRIEVAL_API ). Usage Example Create an EmailRetriever instance by providing the necessary credentials and client information. Call getEmailsInFolder with the appropriate parameters to retrieve emails from a specified folder.","title":"Email"},{"location":"api/email/#email","text":"The EmailRetriever class in Node.js is designed to retrieve emails from different email clients using SMTP configurations.","title":"Email"},{"location":"api/email/#class-emailretriever","text":"","title":"Class: EmailRetriever"},{"location":"api/email/#constructor","text":"Parameters : emailAddress (String): The email address of the account. emailPassword (String): The password of the account. emailClient (String): The email client hosting the email address (e.g., \"gmail\", \"outlook\"). verbose (Boolean): Optional flag for verbose error logging. Description : Initializes the EmailRetriever with the provided email address, password, and client. Validates and sets the SMTP configuration based on the email client.","title":"Constructor"},{"location":"api/email/#method-getemailsinfolderfoldername-limit-imapsearchcommand","text":"Parameters : folderName (String): The name of the folder to scan in the email account. limit (String): Maximum number of emails to retrieve. IMAPSearchCommand (String): The IMAP search command (e.g., \"ALL\", \"UNSEEN\", \"SEEN\"). Returns : Array of emails or undefined. Description : Retrieves emails from a specific folder in the user's email account. Utilizes an external API for email retrieval. Handles and reports errors, especially if verbose is enabled.","title":"Method: getEmailsInFolder(folderName, limit, IMAPSearchCommand)"},{"location":"api/email/#additional-information","text":"SMTP Configuration Constants : The class uses predefined SMTP configurations for supported email clients, which are stored in emailClientSMTPConfigs . Error Handling : The class throws an error if the specified email client is not supported. External API Usage : Email retrieval is performed through a call to a specified external API ( EMAIL_RETRIEVAL_API ).","title":"Additional Information"},{"location":"api/email/#usage-example","text":"Create an EmailRetriever instance by providing the necessary credentials and client information. Call getEmailsInFolder with the appropriate parameters to retrieve emails from a specified folder.","title":"Usage Example"},{"location":"api/firestore/","text":"Firestore The Firestore class in Node.js provides functionalities for interacting with Firebase Firestore, including querying, adding, updating, and deleting documents. Class: Firestore Constructor Parameters : props (Object) containing the Firestore database instance. Description : Initializes the Firestore class with a database instance. Method: filterCollectionWithWhereClause(...) Purpose : Filters a collection using a where clause. Returns : Array of documents matching the filter. Method: filterCollectionWithWhereClauseIncludeDocID(...) Purpose : Similar to filterCollectionWithWhereClause , but includes document IDs in the results. Returns : Array of documents with their document IDs. Method: filterCollectionWithWhereClauseWithID(...) Purpose : Filters a collection and returns only the document IDs. Returns : Array of document IDs. Method: addDocumentToCollection(...) Purpose : Adds a document to a specified collection. Returns : Object containing the success status and document ID. Method: createDocIfNotExist(...) Purpose : Creates a document in a collection if it does not exist. Returns : Boolean indicating the document's creation status. Method: updateDocument(...) Purpose : Updates a document in a collection. Returns : Object containing the success status. Method: updateDocumentInSubcollection(...) Purpose : Updates a document in a subcollection. Returns : Object containing the success status. Method: deleteDocumentFromCollection(...) Purpose : Deletes a document from a collection. Returns : Object containing the success status. Method: filterCollectionWithMultipleWhereClause(...) Purpose : Filters a collection using multiple where clauses. Returns : Array of documents matching the filters. Method: filterCollectionWithMultipleWhereClauseWithLimit(...) Purpose : Filters a collection using multiple where clauses with a limit on the number of documents. Returns : Array of documents matching the filters. Method: filterCollectionWithMultipleWhereClauseIncludeDocID(...) Purpose : Filters a collection using multiple where clauses and includes document IDs. Returns : Array of documents with their document IDs. Method: filterSubCollectionWithMultipleWhereClauseIncludeDocID(...) Purpose : Filters a subcollection using multiple where clauses and includes document IDs. Returns : Array of documents with their document IDs. Method: runTransactionUpdate(...) Purpose : Runs a transaction to update a document in Firestore. Returns : Boolean indicating the success of the transaction. Method: addDocumentToSubCollection(...) Purpose : Adds a document to a subcollection. Returns : Object containing the success status and document ID. Method: addDocumentToSubCollectionWithCustomId(...) Purpose : Adds a document to a subcollection with a custom document ID. Returns : Object containing the success status and document ID. Method: getDocInCollection(...) Purpose : Retrieves a document from a collection. Returns : Document data or undefined . Method: addDocumentToCollectionWithCustomId(...) Purpose : Adds a document to a collection with a custom document ID. Returns : Object containing the success status and document ID. Method: incrementCountByTransaction(...) Purpose : Increments a count field in a document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction. Method: incrementIntFieldbyTransaction(...) Purpose : Increments an integer field in a document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction. Method: incrementCountByTransactionSubCollection(...) Purpose : Increments a count field in a subcollection document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction. Method: updateFieldbyTransactionSubCollection(...) Purpose : Updates a field in a subcollection document using a transaction. Returns : Boolean indicating the success of the transaction. Method: getAllDocumentsInCollection(...) Purpose : Retrieves all documents in a specified collection. Returns : Array of documents. Method: getTotalNumDocumentsInCollection(...) Purpose : Gets the total number of documents in a collection. Returns : Integer representing the total number of documents. Method: getNumberOfDocumentsInSubCollection(...) Purpose : Gets the number of documents in a subcollection. Returns : Integer representing the total number of documents. Method: getFieldInSubCollection(...) Purpose : Retrieves a specific","title":"Firestore"},{"location":"api/firestore/#firestore","text":"The Firestore class in Node.js provides functionalities for interacting with Firebase Firestore, including querying, adding, updating, and deleting documents.","title":"Firestore"},{"location":"api/firestore/#class-firestore","text":"","title":"Class: Firestore"},{"location":"api/firestore/#constructor","text":"Parameters : props (Object) containing the Firestore database instance. Description : Initializes the Firestore class with a database instance.","title":"Constructor"},{"location":"api/firestore/#method-filtercollectionwithwhereclause","text":"Purpose : Filters a collection using a where clause. Returns : Array of documents matching the filter.","title":"Method: filterCollectionWithWhereClause(...)"},{"location":"api/firestore/#method-filtercollectionwithwhereclauseincludedocid","text":"Purpose : Similar to filterCollectionWithWhereClause , but includes document IDs in the results. Returns : Array of documents with their document IDs.","title":"Method: filterCollectionWithWhereClauseIncludeDocID(...)"},{"location":"api/firestore/#method-filtercollectionwithwhereclausewithid","text":"Purpose : Filters a collection and returns only the document IDs. Returns : Array of document IDs.","title":"Method: filterCollectionWithWhereClauseWithID(...)"},{"location":"api/firestore/#method-adddocumenttocollection","text":"Purpose : Adds a document to a specified collection. Returns : Object containing the success status and document ID.","title":"Method: addDocumentToCollection(...)"},{"location":"api/firestore/#method-createdocifnotexist","text":"Purpose : Creates a document in a collection if it does not exist. Returns : Boolean indicating the document's creation status.","title":"Method: createDocIfNotExist(...)"},{"location":"api/firestore/#method-updatedocument","text":"Purpose : Updates a document in a collection. Returns : Object containing the success status.","title":"Method: updateDocument(...)"},{"location":"api/firestore/#method-updatedocumentinsubcollection","text":"Purpose : Updates a document in a subcollection. Returns : Object containing the success status.","title":"Method: updateDocumentInSubcollection(...)"},{"location":"api/firestore/#method-deletedocumentfromcollection","text":"Purpose : Deletes a document from a collection. Returns : Object containing the success status.","title":"Method: deleteDocumentFromCollection(...)"},{"location":"api/firestore/#method-filtercollectionwithmultiplewhereclause","text":"Purpose : Filters a collection using multiple where clauses. Returns : Array of documents matching the filters.","title":"Method: filterCollectionWithMultipleWhereClause(...)"},{"location":"api/firestore/#method-filtercollectionwithmultiplewhereclausewithlimit","text":"Purpose : Filters a collection using multiple where clauses with a limit on the number of documents. Returns : Array of documents matching the filters.","title":"Method: filterCollectionWithMultipleWhereClauseWithLimit(...)"},{"location":"api/firestore/#method-filtercollectionwithmultiplewhereclauseincludedocid","text":"Purpose : Filters a collection using multiple where clauses and includes document IDs. Returns : Array of documents with their document IDs.","title":"Method: filterCollectionWithMultipleWhereClauseIncludeDocID(...)"},{"location":"api/firestore/#method-filtersubcollectionwithmultiplewhereclauseincludedocid","text":"Purpose : Filters a subcollection using multiple where clauses and includes document IDs. Returns : Array of documents with their document IDs.","title":"Method: filterSubCollectionWithMultipleWhereClauseIncludeDocID(...)"},{"location":"api/firestore/#method-runtransactionupdate","text":"Purpose : Runs a transaction to update a document in Firestore. Returns : Boolean indicating the success of the transaction.","title":"Method: runTransactionUpdate(...)"},{"location":"api/firestore/#method-adddocumenttosubcollection","text":"Purpose : Adds a document to a subcollection. Returns : Object containing the success status and document ID.","title":"Method: addDocumentToSubCollection(...)"},{"location":"api/firestore/#method-adddocumenttosubcollectionwithcustomid","text":"Purpose : Adds a document to a subcollection with a custom document ID. Returns : Object containing the success status and document ID.","title":"Method: addDocumentToSubCollectionWithCustomId(...)"},{"location":"api/firestore/#method-getdocincollection","text":"Purpose : Retrieves a document from a collection. Returns : Document data or undefined .","title":"Method: getDocInCollection(...)"},{"location":"api/firestore/#method-adddocumenttocollectionwithcustomid","text":"Purpose : Adds a document to a collection with a custom document ID. Returns : Object containing the success status and document ID.","title":"Method: addDocumentToCollectionWithCustomId(...)"},{"location":"api/firestore/#method-incrementcountbytransaction","text":"Purpose : Increments a count field in a document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction.","title":"Method: incrementCountByTransaction(...)"},{"location":"api/firestore/#method-incrementintfieldbytransaction","text":"Purpose : Increments an integer field in a document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction.","title":"Method: incrementIntFieldbyTransaction(...)"},{"location":"api/firestore/#method-incrementcountbytransactionsubcollection","text":"Purpose : Increments a count field in a subcollection document by a specified value using a transaction. Returns : Boolean indicating the success of the transaction.","title":"Method: incrementCountByTransactionSubCollection(...)"},{"location":"api/firestore/#method-updatefieldbytransactionsubcollection","text":"Purpose : Updates a field in a subcollection document using a transaction. Returns : Boolean indicating the success of the transaction.","title":"Method: updateFieldbyTransactionSubCollection(...)"},{"location":"api/firestore/#method-getalldocumentsincollection","text":"Purpose : Retrieves all documents in a specified collection. Returns : Array of documents.","title":"Method: getAllDocumentsInCollection(...)"},{"location":"api/firestore/#method-gettotalnumdocumentsincollection","text":"Purpose : Gets the total number of documents in a collection. Returns : Integer representing the total number of documents.","title":"Method: getTotalNumDocumentsInCollection(...)"},{"location":"api/firestore/#method-getnumberofdocumentsinsubcollection","text":"Purpose : Gets the number of documents in a subcollection. Returns : Integer representing the total number of documents.","title":"Method: getNumberOfDocumentsInSubCollection(...)"},{"location":"api/firestore/#method-getfieldinsubcollection","text":"Purpose : Retrieves a specific","title":"Method: getFieldInSubCollection(...)"},{"location":"api/gdrive/","text":"DriveUtils The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs. Class: DriveUtils Constructor Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web). Method: getDrive() Returns : Google Drive instance. Description : Initializes and retrieves the Google Drive instance. Method: listFilez() Description : Lists files in Google Drive with a predefined page size and fields. Method: listFiles(props) Parameters : props (Object) containing file listing options. Returns : File list or error information. Description : Lists files in Google Drive based on various properties like directory, mime type, etc. Method: listDirectories(props) Parameters : props (Object) for directory listing. Returns : Directory list or error information. Description : Lists all directories or directories within a specific directory. Method: getFileInfo(props) Parameters : props (Object) containing file information options. Returns : File information or error. Description : Retrieves information about a specific file based on provided criteria. Method: getFileById(props) Parameters : props (Object) containing file ID. Returns : File data or error. Description : Retrieves a file by its ID. Method: getFileByName(props) Parameters : props (Object) containing file name and other options. Returns : File data or error. Description : Retrieves a file by its name. Method: createFile(props) Parameters : props (Object) containing file creation options. Returns : File creation result. Description : Creates a file in Google Drive. Method: createAndOrGetContent(props) Parameters : props (Object) containing file path and content options. Returns : File or directory content. Description : Creates or retrieves content based on a given path and other criteria. Method: updateFile(props) Parameters : props (Object) containing file update options. Returns : File update result. Description : Updates a file in Google Drive. Static Method: getAuthUrl(config) Parameters : config (Object) for authentication URL generation. Returns : Authentication URL. Description : Generates a Google authentication URL for obtaining access tokens. Static Method: handleAuthCallback(config) Parameters : config (Object) containing authentication callback information. Returns : Tokens or false. Description : Handles the authentication callback from Google to get access tokens. Static Method: checkAndRefresh(config) Parameters : config (Object) for token check and refresh. Returns : Access token or false. Description : Checks and refreshes the access token if it is expired. Static Method: refreshToken(config) Parameters : config (Object) for token refresh. Returns : New access token. Description : Refreshes the access token. Comments and Additional Information The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to file operations.","title":"DriveUtils"},{"location":"api/gdrive/#driveutils","text":"The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs.","title":"DriveUtils"},{"location":"api/gdrive/#class-driveutils","text":"","title":"Class: DriveUtils"},{"location":"api/gdrive/#constructor","text":"Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web).","title":"Constructor"},{"location":"api/gdrive/#method-getdrive","text":"Returns : Google Drive instance. Description : Initializes and retrieves the Google Drive instance.","title":"Method: getDrive()"},{"location":"api/gdrive/#method-listfilez","text":"Description : Lists files in Google Drive with a predefined page size and fields.","title":"Method: listFilez()"},{"location":"api/gdrive/#method-listfilesprops","text":"Parameters : props (Object) containing file listing options. Returns : File list or error information. Description : Lists files in Google Drive based on various properties like directory, mime type, etc.","title":"Method: listFiles(props)"},{"location":"api/gdrive/#method-listdirectoriesprops","text":"Parameters : props (Object) for directory listing. Returns : Directory list or error information. Description : Lists all directories or directories within a specific directory.","title":"Method: listDirectories(props)"},{"location":"api/gdrive/#method-getfileinfoprops","text":"Parameters : props (Object) containing file information options. Returns : File information or error. Description : Retrieves information about a specific file based on provided criteria.","title":"Method: getFileInfo(props)"},{"location":"api/gdrive/#method-getfilebyidprops","text":"Parameters : props (Object) containing file ID. Returns : File data or error. Description : Retrieves a file by its ID.","title":"Method: getFileById(props)"},{"location":"api/gdrive/#method-getfilebynameprops","text":"Parameters : props (Object) containing file name and other options. Returns : File data or error. Description : Retrieves a file by its name.","title":"Method: getFileByName(props)"},{"location":"api/gdrive/#method-createfileprops","text":"Parameters : props (Object) containing file creation options. Returns : File creation result. Description : Creates a file in Google Drive.","title":"Method: createFile(props)"},{"location":"api/gdrive/#method-createandorgetcontentprops","text":"Parameters : props (Object) containing file path and content options. Returns : File or directory content. Description : Creates or retrieves content based on a given path and other criteria.","title":"Method: createAndOrGetContent(props)"},{"location":"api/gdrive/#method-updatefileprops","text":"Parameters : props (Object) containing file update options. Returns : File update result. Description : Updates a file in Google Drive.","title":"Method: updateFile(props)"},{"location":"api/gdrive/#static-method-getauthurlconfig","text":"Parameters : config (Object) for authentication URL generation. Returns : Authentication URL. Description : Generates a Google authentication URL for obtaining access tokens.","title":"Static Method: getAuthUrl(config)"},{"location":"api/gdrive/#static-method-handleauthcallbackconfig","text":"Parameters : config (Object) containing authentication callback information. Returns : Tokens or false. Description : Handles the authentication callback from Google to get access tokens.","title":"Static Method: handleAuthCallback(config)"},{"location":"api/gdrive/#static-method-checkandrefreshconfig","text":"Parameters : config (Object) for token check and refresh. Returns : Access token or false. Description : Checks and refreshes the access token if it is expired.","title":"Static Method: checkAndRefresh(config)"},{"location":"api/gdrive/#static-method-refreshtokenconfig","text":"Parameters : config (Object) for token refresh. Returns : New access token. Description : Refreshes the access token.","title":"Static Method: refreshToken(config)"},{"location":"api/gdrive/#comments-and-additional-information","text":"The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to file operations.","title":"Comments and Additional Information"},{"location":"api/heroku/","text":"Heroku The HerokuHandler class in Node.js is designed to interact with the Heroku API. It facilitates checking the installation and login status on Heroku, and allows for additional functionality related to Heroku operations. Class: HerokuHandler Constructor Parameters : props (Object): Contains herokuApiKey , username , and password . Description : Initializes the class with Heroku API key and user credentials. Method: checkInstall() Returns : Boolean indicating if Heroku CLI is installed. Description : Checks if the Heroku CLI is installed by making a GET request to the Heroku API. Logs the CLI version or error message. Method: checkLogin() Returns : Boolean indicating if the user is logged into Heroku. Description : Verifies if the user is logged in to Heroku by making a GET request to the Heroku account API endpoint. Logs the email address of the logged-in user or error message. Static Method: handleHeroku(args) Parameters : args (Object) - Heroku configuration arguments. Returns : Object with the status and message regarding Heroku installation and login. Description : Handles Heroku operations by creating an instance of HerokuHandler and checking both installation and login status. Logs the status of Heroku installation and user login. Export The HerokuHandler class is exported for use in other modules. Additional Comments The class contains commented-out code, which provides an alternative approach using exec and spawn commands for interacting with the Heroku CLI. The commented section outlines additional potential functionalities, like installation and login via CLI commands, which are currently benched in favor of REST API interactions. The comments also provide insights into the Heroku login command behavior, particularly regarding multi-factor authentication (MFA) and API token handling.","title":"Heroku"},{"location":"api/heroku/#heroku","text":"The HerokuHandler class in Node.js is designed to interact with the Heroku API. It facilitates checking the installation and login status on Heroku, and allows for additional functionality related to Heroku operations.","title":"Heroku"},{"location":"api/heroku/#class-herokuhandler","text":"","title":"Class: HerokuHandler"},{"location":"api/heroku/#constructor","text":"Parameters : props (Object): Contains herokuApiKey , username , and password . Description : Initializes the class with Heroku API key and user credentials.","title":"Constructor"},{"location":"api/heroku/#method-checkinstall","text":"Returns : Boolean indicating if Heroku CLI is installed. Description : Checks if the Heroku CLI is installed by making a GET request to the Heroku API. Logs the CLI version or error message.","title":"Method: checkInstall()"},{"location":"api/heroku/#method-checklogin","text":"Returns : Boolean indicating if the user is logged into Heroku. Description : Verifies if the user is logged in to Heroku by making a GET request to the Heroku account API endpoint. Logs the email address of the logged-in user or error message.","title":"Method: checkLogin()"},{"location":"api/heroku/#static-method-handleherokuargs","text":"Parameters : args (Object) - Heroku configuration arguments. Returns : Object with the status and message regarding Heroku installation and login. Description : Handles Heroku operations by creating an instance of HerokuHandler and checking both installation and login status. Logs the status of Heroku installation and user login.","title":"Static Method: handleHeroku(args)"},{"location":"api/heroku/#export","text":"The HerokuHandler class is exported for use in other modules.","title":"Export"},{"location":"api/heroku/#additional-comments","text":"The class contains commented-out code, which provides an alternative approach using exec and spawn commands for interacting with the Heroku CLI. The commented section outlines additional potential functionalities, like installation and login via CLI commands, which are currently benched in favor of REST API interactions. The comments also provide insights into the Heroku login command behavior, particularly regarding multi-factor authentication (MFA) and API token handling.","title":"Additional Comments"},{"location":"api/huggingFace/","text":"HuggingFace Documentation The HuggingFace class is a wrapper around the HfInference class from @huggingface/inference and some functions ( createRepo , uploadFile , deleteFiles ) from @huggingface/hub . This class provides methods that enable users to perform actions such as validating tokens, checking if a hub exists, asking questions, creating repositories, uploading files, and deleting files on the Hugging Face platform. Method: tokenIsValid() This method checks if the provided access token is valid by making an inference call using the token. This method can help to avoid problems further down the line by ensuring that the token is valid before performing any operation. Returns : A boolean indicating whether the token is valid (true) or invalid (false). Description : The method lists the models available on the Hugging Face platform and, based on the success or failure of this operation, it returns a boolean. If an error occurs during the execution of the method, this error is logged and the method returns false . Parameters : This method has no parameters. Method: hubExists() This method is used to check if a hub exists on the Hugging Face platform. Returns : A boolean indicating whether the hub exists (true) or not (false). Description : This method works by listing the models of the Hugging Face platform and, based on the success or failure of this operation, it returns a boolean. If an error occurs during the execution of the method, this error is logged and the method returns false . Parameters : This method does not take any parameters. Method: questionAnswering(model, inputs) This method runs a question answering model on Hugging Face, using the provided model and inputs. Returns : The result of the question answering model inference. Description : This method uses the questionAnswer method from the HfInference instance ( this.inference ) to answer questions. Parameters : Parameter Name Description Accepted Values/Data Types model The model to be used String inputs The inputs to the model String Method: createRepo(repoPath, type) Returns : The response from the createRepo function from the @huggingface/hub package. Description : This method is used to create a new repository or folder on the Hugging Face hub. Parameters : Parameter Name Description Accepted Values/Data Types repoPath The path to the new repository String type The type of the new repository String For more methods like uploadFile , deleteFiles , etc., the template provided above should be followed to document them.","title":"HuggingFace"},{"location":"api/huggingFace/#huggingface-documentation","text":"The HuggingFace class is a wrapper around the HfInference class from @huggingface/inference and some functions ( createRepo , uploadFile , deleteFiles ) from @huggingface/hub . This class provides methods that enable users to perform actions such as validating tokens, checking if a hub exists, asking questions, creating repositories, uploading files, and deleting files on the Hugging Face platform.","title":"HuggingFace Documentation"},{"location":"api/huggingFace/#method-tokenisvalid","text":"This method checks if the provided access token is valid by making an inference call using the token. This method can help to avoid problems further down the line by ensuring that the token is valid before performing any operation. Returns : A boolean indicating whether the token is valid (true) or invalid (false). Description : The method lists the models available on the Hugging Face platform and, based on the success or failure of this operation, it returns a boolean. If an error occurs during the execution of the method, this error is logged and the method returns false . Parameters : This method has no parameters.","title":"Method: tokenIsValid()"},{"location":"api/huggingFace/#method-hubexists","text":"This method is used to check if a hub exists on the Hugging Face platform. Returns : A boolean indicating whether the hub exists (true) or not (false). Description : This method works by listing the models of the Hugging Face platform and, based on the success or failure of this operation, it returns a boolean. If an error occurs during the execution of the method, this error is logged and the method returns false . Parameters : This method does not take any parameters.","title":"Method: hubExists()"},{"location":"api/huggingFace/#method-questionansweringmodel-inputs","text":"This method runs a question answering model on Hugging Face, using the provided model and inputs. Returns : The result of the question answering model inference. Description : This method uses the questionAnswer method from the HfInference instance ( this.inference ) to answer questions. Parameters : Parameter Name Description Accepted Values/Data Types model The model to be used String inputs The inputs to the model String","title":"Method: questionAnswering(model, inputs)"},{"location":"api/huggingFace/#method-createreporepopath-type","text":"Returns : The response from the createRepo function from the @huggingface/hub package. Description : This method is used to create a new repository or folder on the Hugging Face hub. Parameters : Parameter Name Description Accepted Values/Data Types repoPath The path to the new repository String type The type of the new repository String For more methods like uploadFile , deleteFiles , etc., the template provided above should be followed to document them.","title":"Method: createRepo(repoPath, type)"},{"location":"api/huggingFace_og/","text":"HuggingFace The HuggingFace class in Node.js facilitates interaction with the Hugging Face API for operations such as validating tokens, managing repositories, uploading files, and performing model inference. Class: HuggingFace Constructor Parameters : accessToken (String): Access token for Hugging Face API. defaultOptions (Object): Default options for the class. Description : Initializes the class with the provided access token and default options. Sets up an instance of HfInference for model inference tasks. Method: tokenIsValid() Returns : Boolean indicating if the token is valid. Description : Validates the provided access token by attempting to list models. Logs the process and errors if any. Method: hubExists() Returns : Boolean indicating if the hub exists. Description : Checks for the existence of a hub by attempting to list models. Handles and logs any errors encountered. Method: questionAnswering(model, inputs) Parameters : model (String): The model to use for question answering. inputs (String): The inputs for the model. Returns : The result of the question answering model. Description : Calls a question-answering model on the Hugging Face platform. Returns the model's response. Method: createRepo(repoPath, type) Parameters : repoPath (String): The path to the repository. type (String): The type of repository. Returns : Result of repository creation. Description : Creates a repository or folder in the Hugging Face hub. Handles different repository types. Method: uploadFile(repoPath, filePath, blob) Parameters : repoPath (String): The repository path. filePath (String): The file path. blob (Blob): The file content. Returns : Result of file upload. Description : Uploads a file to the specified repository in the Hugging Face hub. Method: deleteFiles(type, name, paths) Parameters : type (String): Type of repository or space. name (String): The path to the repo or space. paths (Array): File paths to delete. Returns : Result of file deletion. Description : Deletes files in the specified repository or space on the Hugging Face hub. Export The HuggingFace class is exported for use in other modules. Comments and TODOs The code includes TODO comments outlining future goals like updating models, connecting models to inference endpoints, checking for space existence, and managing space resources. These comments link to relevant documentation for further guidance on these tasks.","title":"HuggingFace"},{"location":"api/huggingFace_og/#huggingface","text":"The HuggingFace class in Node.js facilitates interaction with the Hugging Face API for operations such as validating tokens, managing repositories, uploading files, and performing model inference.","title":"HuggingFace"},{"location":"api/huggingFace_og/#class-huggingface","text":"","title":"Class: HuggingFace"},{"location":"api/huggingFace_og/#constructor","text":"Parameters : accessToken (String): Access token for Hugging Face API. defaultOptions (Object): Default options for the class. Description : Initializes the class with the provided access token and default options. Sets up an instance of HfInference for model inference tasks.","title":"Constructor"},{"location":"api/huggingFace_og/#method-tokenisvalid","text":"Returns : Boolean indicating if the token is valid. Description : Validates the provided access token by attempting to list models. Logs the process and errors if any.","title":"Method: tokenIsValid()"},{"location":"api/huggingFace_og/#method-hubexists","text":"Returns : Boolean indicating if the hub exists. Description : Checks for the existence of a hub by attempting to list models. Handles and logs any errors encountered.","title":"Method: hubExists()"},{"location":"api/huggingFace_og/#method-questionansweringmodel-inputs","text":"Parameters : model (String): The model to use for question answering. inputs (String): The inputs for the model. Returns : The result of the question answering model. Description : Calls a question-answering model on the Hugging Face platform. Returns the model's response.","title":"Method: questionAnswering(model, inputs)"},{"location":"api/huggingFace_og/#method-createreporepopath-type","text":"Parameters : repoPath (String): The path to the repository. type (String): The type of repository. Returns : Result of repository creation. Description : Creates a repository or folder in the Hugging Face hub. Handles different repository types.","title":"Method: createRepo(repoPath, type)"},{"location":"api/huggingFace_og/#method-uploadfilerepopath-filepath-blob","text":"Parameters : repoPath (String): The repository path. filePath (String): The file path. blob (Blob): The file content. Returns : Result of file upload. Description : Uploads a file to the specified repository in the Hugging Face hub.","title":"Method: uploadFile(repoPath, filePath, blob)"},{"location":"api/huggingFace_og/#method-deletefilestype-name-paths","text":"Parameters : type (String): Type of repository or space. name (String): The path to the repo or space. paths (Array): File paths to delete. Returns : Result of file deletion. Description : Deletes files in the specified repository or space on the Hugging Face hub.","title":"Method: deleteFiles(type, name, paths)"},{"location":"api/huggingFace_og/#export","text":"The HuggingFace class is exported for use in other modules.","title":"Export"},{"location":"api/huggingFace_og/#comments-and-todos","text":"The code includes TODO comments outlining future goals like updating models, connecting models to inference endpoints, checking for space existence, and managing space resources. These comments link to relevant documentation for further guidance on these tasks.","title":"Comments and TODOs"},{"location":"api/llmOverview/","text":"LLM Overview Welcome to the LLM Overview! Here, we delve into the intricacies and unique features of several Node.js classes. Our goal is to offer you an engaging and informative guide through their functionalities and capabilities, making your development journey both efficient and enjoyable. HuggingFace Class Overview Class: HuggingFace The HuggingFace class is your gateway to interacting with the innovative Hugging Face API. From validating tokens and managing repositories to uploading files and performing model inference, this class is equipped to handle it all with ease. Constructor Parameters : accessToken (String): Your key to access the diverse features of the Hugging Face API. defaultOptions (Object): Customize the class behavior to suit your needs. Key Methods tokenIsValid() : Wondering about your token's validity? This method swiftly confirms it for you. hubExists() : Check if your desired hub is up and running with a simple call. questionAnswering(model, inputs) : Dive into AI-driven question answering with your chosen model. createRepo(repoPath, type) : Setting up a new repository is just a few parameters away. uploadFile(repoPath, filePath, blob) : Easily upload files to your repository in the Hugging Face hub. deleteFiles(type, name, paths) : Need to clear some space? Delete files seamlessly with this method. HerokuHandler Class Overview Class: HerokuHandler Embark on a smooth journey with Heroku using the HerokuHandler class. It simplifies interactions with the Heroku API, ensuring you can check installation and login statuses effortlessly. Constructor Parameters : props (Object): All you need to connect - Heroku API key, username, and password. Key Methods checkInstall() : Quickly verify if Heroku CLI is part of your toolkit. checkLogin() : Log in hassles? This method ensures you're connected to Heroku. handleHeroku(args) : Manage your Heroku setup and status with this comprehensive function. NPM: Langdrive: DriveChatbot Class Overview Chatbot Primarily for demonstration and testing purposes. Engage with the DriveChatbot , where Async Promises bring your chatbot interactions to life. Train Class Overview Class: Train The Train class is your companion in the realm of machine learning. It's designed to streamline the training process of your models and manage data sources efficiently. Constructor Parameters : props (Object): Fine-tune your training experience with verbose and train options. Key Methods init(config) : Initializes the class and prepares data. trainModel(huggingfaceInfo) : Manages the model training process. prepareData() : Prepares training data. getDataFromUrl(url) : Fetches data from a URL. getDataFromService(classInstance, query) : Retrieves data using a service class. getValuesFromData(data, value) : Extracts specific values from data. getData(lbl) : General method for data retrieval. Utils Script Overview Script: utils This Node.js script is essential for deploying machine learning models. It utilizes key libraries like fs , path , js-yaml , and dotenv for various file operations, path resolution, YAML processing, and environment variable management. Main Functions cli_deploy(args) : Entry point for deploying the model. Manages deployment initiation and configuration retrieval. deploy(config) : Handles the core deployment process of the machine learning model. getConfig(args) : Retrieves deployment configurations from a YAML file. Modules fs : Handles file system operations. path : Manages file paths. js-yaml : Processes YAML files. dotenv : Loads environment variables.","title":"Overview"},{"location":"api/llmOverview/#llm-overview","text":"Welcome to the LLM Overview! Here, we delve into the intricacies and unique features of several Node.js classes. Our goal is to offer you an engaging and informative guide through their functionalities and capabilities, making your development journey both efficient and enjoyable.","title":"LLM Overview"},{"location":"api/llmOverview/#huggingface-class-overview","text":"","title":"HuggingFace Class Overview"},{"location":"api/llmOverview/#class-huggingface","text":"The HuggingFace class is your gateway to interacting with the innovative Hugging Face API. From validating tokens and managing repositories to uploading files and performing model inference, this class is equipped to handle it all with ease.","title":"Class: HuggingFace"},{"location":"api/llmOverview/#constructor","text":"Parameters : accessToken (String): Your key to access the diverse features of the Hugging Face API. defaultOptions (Object): Customize the class behavior to suit your needs.","title":"Constructor"},{"location":"api/llmOverview/#key-methods","text":"tokenIsValid() : Wondering about your token's validity? This method swiftly confirms it for you. hubExists() : Check if your desired hub is up and running with a simple call. questionAnswering(model, inputs) : Dive into AI-driven question answering with your chosen model. createRepo(repoPath, type) : Setting up a new repository is just a few parameters away. uploadFile(repoPath, filePath, blob) : Easily upload files to your repository in the Hugging Face hub. deleteFiles(type, name, paths) : Need to clear some space? Delete files seamlessly with this method.","title":"Key Methods"},{"location":"api/llmOverview/#herokuhandler-class-overview","text":"","title":"HerokuHandler Class Overview"},{"location":"api/llmOverview/#class-herokuhandler","text":"Embark on a smooth journey with Heroku using the HerokuHandler class. It simplifies interactions with the Heroku API, ensuring you can check installation and login statuses effortlessly.","title":"Class: HerokuHandler"},{"location":"api/llmOverview/#constructor_1","text":"Parameters : props (Object): All you need to connect - Heroku API key, username, and password.","title":"Constructor"},{"location":"api/llmOverview/#key-methods_1","text":"checkInstall() : Quickly verify if Heroku CLI is part of your toolkit. checkLogin() : Log in hassles? This method ensures you're connected to Heroku. handleHeroku(args) : Manage your Heroku setup and status with this comprehensive function.","title":"Key Methods"},{"location":"api/llmOverview/#npm-langdrive-drivechatbot-class-overview","text":"","title":"NPM: Langdrive: DriveChatbot Class Overview"},{"location":"api/llmOverview/#chatbot","text":"Primarily for demonstration and testing purposes. Engage with the DriveChatbot , where Async Promises bring your chatbot interactions to life.","title":"Chatbot"},{"location":"api/llmOverview/#train-class-overview","text":"","title":"Train Class Overview"},{"location":"api/llmOverview/#class-train","text":"The Train class is your companion in the realm of machine learning. It's designed to streamline the training process of your models and manage data sources efficiently.","title":"Class: Train"},{"location":"api/llmOverview/#constructor_2","text":"Parameters : props (Object): Fine-tune your training experience with verbose and train options.","title":"Constructor"},{"location":"api/llmOverview/#key-methods_2","text":"init(config) : Initializes the class and prepares data. trainModel(huggingfaceInfo) : Manages the model training process. prepareData() : Prepares training data. getDataFromUrl(url) : Fetches data from a URL. getDataFromService(classInstance, query) : Retrieves data using a service class. getValuesFromData(data, value) : Extracts specific values from data. getData(lbl) : General method for data retrieval.","title":"Key Methods"},{"location":"api/llmOverview/#utils-script-overview","text":"","title":"Utils Script Overview"},{"location":"api/llmOverview/#script-utils","text":"This Node.js script is essential for deploying machine learning models. It utilizes key libraries like fs , path , js-yaml , and dotenv for various file operations, path resolution, YAML processing, and environment variable management.","title":"Script: utils"},{"location":"api/llmOverview/#main-functions","text":"cli_deploy(args) : Entry point for deploying the model. Manages deployment initiation and configuration retrieval. deploy(config) : Handles the core deployment process of the machine learning model. getConfig(args) : Retrieves deployment configurations from a YAML file.","title":"Main Functions"},{"location":"api/llmOverview/#modules","text":"fs : Handles file system operations. path : Manages file paths. js-yaml : Processes YAML files. dotenv : Loads environment variables.","title":"Modules"},{"location":"api/overview/","text":"quickstart Should explain the YAML attributes in detail. or have a quick start YAML template. Pass a CSV URL as a data connector of input and output. Put sample CSVs to test Be a page on Docusaurus Document the data connectors and how they work with YAML attributes https://docs.litellm.ai/docs/completion For now: It\u2019s just Firestore, Email, and GDrive Deploy to docusaurus Document deployment options and push to docusaurus HuggingFace and their respective YAML config attributes deploy to huggingace attribute, Document Models Available and how it connects to the YAML config Falcon-7b-sharded And how to configure it in the YAML","title":"Overview"},{"location":"api/train/","text":"Train The Train class in Node.js is designed for handling the training process of a machine learning model, managing data sources, and interacting with external services for data retrieval and model training. Class: Train Constructor Parameters : props (Object) verbose (Boolean): Optional flag to enable verbose logging. train (Object): Contains training-related properties. Description : Initializes the training setup with inputs and outputs. Handles multiple sources for input and output data, such as direct data, paths, services, and queries. Static Method: init(config) Parameters : config (Object) Returns : An instance of the Train class. Description : Static initializer for the class. Prepares data for training by calling prepareData . Method: trainModel(huggingfaceInfo) Parameters : huggingfaceInfo (Object) Returns : Model training result. Description : Handles the training process of the model. Communicates with an external API for model training. Uses huggingfaceInfo for model configuration and deployment. Method: prepareData() Returns : Prepared training data. Description : Prepares input and output data for training. Combines input and output data into a structured format. Method: getDataFromUrl(url) Parameters : url (String) Returns : Data retrieved from the given URL. Description : Retrieves data from a specified URL. Parses CSV data if applicable. Method: getDataFromService(classInstance, query) Parameters : classInstance : Instance of a service class. query : Query object for data retrieval. Returns : Data retrieved from the service. Description : Fetches data using a service class instance and a query. Method: getValuesFromData(data, value) Parameters : data : Raw data array. value : Specific data attribute to extract. Returns : Processed data based on value . Description : Extracts specific values from the provided data. Method: getData(lbl) Parameters : lbl (String) Returns : Retrieved and processed data. Description : General method for data retrieval. Handles different data sources and formats. Export The class Train is exported for use in other modules. Comments The code includes commented sections that outline the expected data formats and arguments for various methods. It also has detailed logging capabilities, especially when the verbose flag is set.","title":"Train"},{"location":"api/train/#train","text":"The Train class in Node.js is designed for handling the training process of a machine learning model, managing data sources, and interacting with external services for data retrieval and model training.","title":"Train"},{"location":"api/train/#class-train","text":"","title":"Class: Train"},{"location":"api/train/#constructor","text":"Parameters : props (Object) verbose (Boolean): Optional flag to enable verbose logging. train (Object): Contains training-related properties. Description : Initializes the training setup with inputs and outputs. Handles multiple sources for input and output data, such as direct data, paths, services, and queries.","title":"Constructor"},{"location":"api/train/#static-method-initconfig","text":"Parameters : config (Object) Returns : An instance of the Train class. Description : Static initializer for the class. Prepares data for training by calling prepareData .","title":"Static Method: init(config)"},{"location":"api/train/#method-trainmodelhuggingfaceinfo","text":"Parameters : huggingfaceInfo (Object) Returns : Model training result. Description : Handles the training process of the model. Communicates with an external API for model training. Uses huggingfaceInfo for model configuration and deployment.","title":"Method: trainModel(huggingfaceInfo)"},{"location":"api/train/#method-preparedata","text":"Returns : Prepared training data. Description : Prepares input and output data for training. Combines input and output data into a structured format.","title":"Method: prepareData()"},{"location":"api/train/#method-getdatafromurlurl","text":"Parameters : url (String) Returns : Data retrieved from the given URL. Description : Retrieves data from a specified URL. Parses CSV data if applicable.","title":"Method: getDataFromUrl(url)"},{"location":"api/train/#method-getdatafromserviceclassinstance-query","text":"Parameters : classInstance : Instance of a service class. query : Query object for data retrieval. Returns : Data retrieved from the service. Description : Fetches data using a service class instance and a query.","title":"Method: getDataFromService(classInstance, query)"},{"location":"api/train/#method-getvaluesfromdatadata-value","text":"Parameters : data : Raw data array. value : Specific data attribute to extract. Returns : Processed data based on value . Description : Extracts specific values from the provided data.","title":"Method: getValuesFromData(data, value)"},{"location":"api/train/#method-getdatalbl","text":"Parameters : lbl (String) Returns : Retrieved and processed data. Description : General method for data retrieval. Handles different data sources and formats.","title":"Method: getData(lbl)"},{"location":"api/train/#export","text":"The class Train is exported for use in other modules.","title":"Export"},{"location":"api/train/#comments","text":"The code includes commented sections that outline the expected data formats and arguments for various methods. It also has detailed logging capabilities, especially when the verbose flag is set.","title":"Comments"},{"location":"api/utils/","text":"utils This documentation outlines the functionality of a Node.js script designed for deploying a machine learning model. Key libraries such as fs , path , js-yaml , and dotenv are used for file system operations, path resolution, YAML processing, and environment variable configuration, respectively. Modules fs : Node.js File System module for handling file operations. path : Node.js Path module for handling file paths. js-yaml : JavaScript library for YAML processing. dotenv : Module for loading environment variables from a .env file. Custom Modules Train : A custom module that likely handles the training of a machine learning model. Main Functions cli_deploy(args) Purpose : Entry point for deploying the model. Prints start log and initiates the deployment process. Parameters : args - Arguments passed from the command line. Process : Logs the initiation of deployment. Retrieves configuration from getConfig function. Calls deploy function with the retrieved configuration. deploy(config) Purpose : Manages the deployment of the machine learning model. Parameters : config - Configuration object for deployment. Process : Logs the start of deployment. Initializes class instances for various services defined in config . Trains the model using the Train module. Handles additional deployment steps (commented out in the provided code). getConfig(args) Purpose : Retrieves configuration settings from a YAML file. Parameters : args - Arguments passed from the command line. Process : Determines the YAML file path based on the provided arguments. Reads and parses the YAML file using js-yaml . Replaces placeholders with environment variable values. Returns the parsed and processed configuration object. Exported Modules The script exports the deploy , getConfig , and cli_deploy functions for external usage. Comments There are commented-out sections in the deploy and getConfig functions which hint at additional functionalities related to services like Heroku and Firebase. The script uses environment variables extensively, indicating a dynamic configuration setup.","title":"utils"},{"location":"api/utils/#utils","text":"This documentation outlines the functionality of a Node.js script designed for deploying a machine learning model. Key libraries such as fs , path , js-yaml , and dotenv are used for file system operations, path resolution, YAML processing, and environment variable configuration, respectively.","title":"utils"},{"location":"api/utils/#modules","text":"fs : Node.js File System module for handling file operations. path : Node.js Path module for handling file paths. js-yaml : JavaScript library for YAML processing. dotenv : Module for loading environment variables from a .env file.","title":"Modules"},{"location":"api/utils/#custom-modules","text":"Train : A custom module that likely handles the training of a machine learning model.","title":"Custom Modules"},{"location":"api/utils/#main-functions","text":"","title":"Main Functions"},{"location":"api/utils/#cli_deployargs","text":"Purpose : Entry point for deploying the model. Prints start log and initiates the deployment process. Parameters : args - Arguments passed from the command line. Process : Logs the initiation of deployment. Retrieves configuration from getConfig function. Calls deploy function with the retrieved configuration.","title":"cli_deploy(args)"},{"location":"api/utils/#deployconfig","text":"Purpose : Manages the deployment of the machine learning model. Parameters : config - Configuration object for deployment. Process : Logs the start of deployment. Initializes class instances for various services defined in config . Trains the model using the Train module. Handles additional deployment steps (commented out in the provided code).","title":"deploy(config)"},{"location":"api/utils/#getconfigargs","text":"Purpose : Retrieves configuration settings from a YAML file. Parameters : args - Arguments passed from the command line. Process : Determines the YAML file path based on the provided arguments. Reads and parses the YAML file using js-yaml . Replaces placeholders with environment variable values. Returns the parsed and processed configuration object.","title":"getConfig(args)"},{"location":"api/utils/#exported-modules","text":"The script exports the deploy , getConfig , and cli_deploy functions for external usage.","title":"Exported Modules"},{"location":"api/utils/#comments","text":"There are commented-out sections in the deploy and getConfig functions which hint at additional functionalities related to services like Heroku and Firebase. The script uses environment variables extensively, indicating a dynamic configuration setup.","title":"Comments"},{"location":"security/authentication/","text":"App Authentication In order to connect to googleDrive you will need proper google app credentials. You can follow these directions to help you get started. Visit this page: https://console.cloud.google.com/apis/credentials You can find it from the google cloud console homepage by clicking \"api's and services\", then clicking \"credentials\" from the tabbed navigation on the left-side of the page that loads. Once on the page, click 'create credentials' -> 'oAuth Client Id'. On the resulting page you will have to select what kind of credentials these are. You may need to visit this page twice because: If you want langDrive to access company resources through a private and secure server. - Select 'desktop app' as your 'app' type If you want user authentication and googleDrive access using langDrive - Select 'Web application' - You will be asked to provide valid js origins from which the oAuth process will occur. Common Options: http://localhost:3000 http://localhost:3000/chat http://localhost:3000/auth http://localhost:3000/auth/callback Once your app is created, a popup will give your a 'desktop app' id and secret, and also an option to 'download json'. Either store the id, secret in your .env file, or provide a path to the jsonString, or even convert the json to a string and use that. you need to point to the drive server file. be sure to rename it because the file comes in funny","title":"App Authentication"},{"location":"security/authentication/#app-authentication","text":"In order to connect to googleDrive you will need proper google app credentials. You can follow these directions to help you get started. Visit this page: https://console.cloud.google.com/apis/credentials You can find it from the google cloud console homepage by clicking \"api's and services\", then clicking \"credentials\" from the tabbed navigation on the left-side of the page that loads. Once on the page, click 'create credentials' -> 'oAuth Client Id'. On the resulting page you will have to select what kind of credentials these are. You may need to visit this page twice because: If you want langDrive to access company resources through a private and secure server. - Select 'desktop app' as your 'app' type If you want user authentication and googleDrive access using langDrive - Select 'Web application' - You will be asked to provide valid js origins from which the oAuth process will occur. Common Options: http://localhost:3000 http://localhost:3000/chat http://localhost:3000/auth http://localhost:3000/auth/callback Once your app is created, a popup will give your a 'desktop app' id and secret, and also an option to 'download json'. Either store the id, secret in your .env file, or provide a path to the jsonString, or even convert the json to a string and use that. you need to point to the drive server file. be sure to rename it because the file comes in funny","title":"App Authentication"},{"location":"security/verification/","text":"App Verification In order to deploy an app that connects to googleDrive, you will typically need higher degrees of app verification. You can follow these directions to help you get started. https://support.google.com/cloud/answer/9110914 If your app requests scopes categorized as sensitive or restricted, you will probably need to complete the verification process (see, however, the exceptions). Depending on the degree of access you need \u2014 read-only, read and write, and so on. Restricted scopes are fewer in number, currently including only scopes used by the Gmail APIs, Drive APIs, and Google Fit APIs. https://developers.google.com/identity/protocols/oauth2/scopes#drive - https://www.googleapis.com/auth/drive - https://www.googleapis.com/auth/drive.readonly - https://www.googleapis.com/auth/drive.activity - https://www.googleapis.com/auth/drive.activity.readonly - https://www.googleapis.com/auth/drive.metadata - https://www.googleapis.com/auth/drive.metadata.readonly - https://www.googleapis.com/auth/drive.scripts If your app requests any of the following scopes, and doesn't meet any of the criteria for an exception (see below), you will need to satisfy both the API Services User Data Policy, the Additional Requirements for Specific Scopes, which may require a more extensive review process. Unverified Apps https://support.google.com/cloud/answer/7454865?hl=en Verification for apps 1. Before you start the verification process, review the OAuth Application Verification FAQ. This will help your verification process go quickly. To start the verification process for apps, do the following steps: Update the OAuth consent screen details in the Google Cloud Platform Console APIs & Services Credentials: You must have a privacy policy URL. Add URLs for your homepage and Terms of Service if you have them. Verify your website ownership through Search Console To start the verification process, submit a verification request by using the following process. a. On the GCP Console OAuth consent screen, click Submit or Save. i. https://console.cloud.google.com/apis/credentials/consent?sjid=413868014423275458-NA b. If a verification required dialog displays: i. Add information in the text boxes for Google to verify your OAuth consent screen. ii. When you're finished entering details, click Submit. Note: If you add any new redirect URLs or JavaScript origins, or if you change your product name after verification, you have to go through verification again. https://developers.google.com/terms/api-services-user-data-policy https://developers.google.com/terms/api-services-user-data-policy#additional_requirements_for_specific_api_scopes https://developers.google.com/terms/ https://developers.google.com/identity/branding-guidelines - if using scopes","title":"App Verification"},{"location":"security/verification/#app-verification","text":"In order to deploy an app that connects to googleDrive, you will typically need higher degrees of app verification. You can follow these directions to help you get started. https://support.google.com/cloud/answer/9110914 If your app requests scopes categorized as sensitive or restricted, you will probably need to complete the verification process (see, however, the exceptions). Depending on the degree of access you need \u2014 read-only, read and write, and so on. Restricted scopes are fewer in number, currently including only scopes used by the Gmail APIs, Drive APIs, and Google Fit APIs. https://developers.google.com/identity/protocols/oauth2/scopes#drive - https://www.googleapis.com/auth/drive - https://www.googleapis.com/auth/drive.readonly - https://www.googleapis.com/auth/drive.activity - https://www.googleapis.com/auth/drive.activity.readonly - https://www.googleapis.com/auth/drive.metadata - https://www.googleapis.com/auth/drive.metadata.readonly - https://www.googleapis.com/auth/drive.scripts If your app requests any of the following scopes, and doesn't meet any of the criteria for an exception (see below), you will need to satisfy both the API Services User Data Policy, the Additional Requirements for Specific Scopes, which may require a more extensive review process. Unverified Apps https://support.google.com/cloud/answer/7454865?hl=en Verification for apps 1. Before you start the verification process, review the OAuth Application Verification FAQ. This will help your verification process go quickly. To start the verification process for apps, do the following steps: Update the OAuth consent screen details in the Google Cloud Platform Console APIs & Services Credentials: You must have a privacy policy URL. Add URLs for your homepage and Terms of Service if you have them. Verify your website ownership through Search Console To start the verification process, submit a verification request by using the following process. a. On the GCP Console OAuth consent screen, click Submit or Save. i. https://console.cloud.google.com/apis/credentials/consent?sjid=413868014423275458-NA b. If a verification required dialog displays: i. Add information in the text boxes for Google to verify your OAuth consent screen. ii. When you're finished entering details, click Submit. Note: If you add any new redirect URLs or JavaScript origins, or if you change your product name after verification, you have to go through verification again. https://developers.google.com/terms/api-services-user-data-policy https://developers.google.com/terms/api-services-user-data-policy#additional_requirements_for_specific_api_scopes https://developers.google.com/terms/ https://developers.google.com/identity/branding-guidelines - if using scopes","title":"App Verification"}]}