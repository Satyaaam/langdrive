{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Langdrive's Documentation Portal Langdrive: Easily train and deploy your favorite models. There are many ways to train and develop LLMs with LangDrive - One way is to configure a YAML doc and by issuing a CLI command. Another way would be importing it as a class modules within a project of your own, YAML doc optional. Whether you're a beginner or an experienced developer, our Data Connectors and LLM tools empower you to build, integrate, and deploy with confidence. Data Connectors help source data from third parties (email, firestore, gdrive) and prepare it for your models. When it comes to training, hosting, and deploying models (Locally, Huggingface, SageMaker, CloudRun), our LLM tools have you covered. All of this is readily available from CLI arguements, a YAML doc, or directly in-code. LangDrive, built specifically for Node.js, makes training and deploying AI models effortless. We provide a library that facilitates data connection and automates training and deployment, ensuring your projects are easy to manage and scale. Read our Getting Started page to jump right in or browse our documentation using the nav below. Data Connectors Overview Get to grips with classes that help you fetch and process data. This includes Firestore for database interactions, Google Drive for file management, and EmailRetriever for fetching emails. Google Drive This section provides a comprehensive look at its constructor, various methods, and how it leverages Google APIs for file operations and authentication. Explore how DriveUtils enhances your Google Drive experience with functionalities covering file listing, information retrieval, and file management. Firestore Designed for robust interaction with Firebase Firestore, learn about its constructor, key methods, and how it can enhance your database interactions. EmailRetriever Tailored for retrieving emails from different email clients using SMTP configurations, discover its constructor, key methods, and additional features. LLM Overview Training and deploying LLMs require resources most of us do not have. That is where our HuggingFace , HerokuHandler , and utils class come into play. These set of classes fascilitate the training and deployment of your LLM. HuggingFace Explore the HuggingFace class, your gateway to interacting with the Hugging Face API. Learn about its constructor, key methods, and how it can simplify your AI-driven tasks. HerokuHandler Understand the HerokuHandler class, which simplifies interactions with the Heroku API. This overview covers its constructor, key methods, and how it can enhance your Heroku experience. Chatbot Discover the DriveChatbot , a demonstration and testing tool for Async Promises in chatbot interactions. Google OAuth2 keys are required to run your own instance. Read our tutorial on OAuth2 on our blog . Utils Understand the essential Node.js script for deploying machine learning models, including its main functions, modules, and how it utilizes various libraries for file operations and environment management. Includes CLI utils. Training This section covers its constructor, key methods, and how it streamlines the training process of your models. Contributing Interested in contributing to LangDrive? Check out our contributing guide . Navigate through our sections to find comprehensive guides and insights that suit your development needs!","title":"About LangDrive"},{"location":"#welcome-to-langdrives-documentation-portal","text":"Langdrive: Easily train and deploy your favorite models. There are many ways to train and develop LLMs with LangDrive - One way is to configure a YAML doc and by issuing a CLI command. Another way would be importing it as a class modules within a project of your own, YAML doc optional. Whether you're a beginner or an experienced developer, our Data Connectors and LLM tools empower you to build, integrate, and deploy with confidence. Data Connectors help source data from third parties (email, firestore, gdrive) and prepare it for your models. When it comes to training, hosting, and deploying models (Locally, Huggingface, SageMaker, CloudRun), our LLM tools have you covered. All of this is readily available from CLI arguements, a YAML doc, or directly in-code. LangDrive, built specifically for Node.js, makes training and deploying AI models effortless. We provide a library that facilitates data connection and automates training and deployment, ensuring your projects are easy to manage and scale. Read our Getting Started page to jump right in or browse our documentation using the nav below.","title":"Welcome to Langdrive's Documentation Portal"},{"location":"#data-connectors-overview","text":"Get to grips with classes that help you fetch and process data. This includes Firestore for database interactions, Google Drive for file management, and EmailRetriever for fetching emails.","title":"Data Connectors Overview"},{"location":"#google-drive","text":"This section provides a comprehensive look at its constructor, various methods, and how it leverages Google APIs for file operations and authentication. Explore how DriveUtils enhances your Google Drive experience with functionalities covering file listing, information retrieval, and file management.","title":"Google Drive"},{"location":"#firestore","text":"Designed for robust interaction with Firebase Firestore, learn about its constructor, key methods, and how it can enhance your database interactions.","title":"Firestore"},{"location":"#emailretriever","text":"Tailored for retrieving emails from different email clients using SMTP configurations, discover its constructor, key methods, and additional features.","title":"EmailRetriever"},{"location":"#llm-overview","text":"Training and deploying LLMs require resources most of us do not have. That is where our HuggingFace , HerokuHandler , and utils class come into play. These set of classes fascilitate the training and deployment of your LLM.","title":"LLM Overview"},{"location":"#huggingface","text":"Explore the HuggingFace class, your gateway to interacting with the Hugging Face API. Learn about its constructor, key methods, and how it can simplify your AI-driven tasks.","title":"HuggingFace"},{"location":"#herokuhandler","text":"Understand the HerokuHandler class, which simplifies interactions with the Heroku API. This overview covers its constructor, key methods, and how it can enhance your Heroku experience.","title":"HerokuHandler"},{"location":"#chatbot","text":"Discover the DriveChatbot , a demonstration and testing tool for Async Promises in chatbot interactions. Google OAuth2 keys are required to run your own instance. Read our tutorial on OAuth2 on our blog .","title":"Chatbot"},{"location":"#utils","text":"Understand the essential Node.js script for deploying machine learning models, including its main functions, modules, and how it utilizes various libraries for file operations and environment management. Includes CLI utils.","title":"Utils"},{"location":"#training","text":"This section covers its constructor, key methods, and how it streamlines the training process of your models.","title":"Training"},{"location":"#contributing","text":"Interested in contributing to LangDrive? Check out our contributing guide . Navigate through our sections to find comprehensive guides and insights that suit your development needs!","title":"Contributing"},{"location":"cli/","text":"Command Line Interface Simply: Install Langdrive: npm isntall langdrive Train a model: `langdrive train` + [...Args]` Here are your Args: yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training data. The training data should be a two-column CSV of input and output pairs. hfToken : An API key provided by Hugging Face with write permissions. Get one here . baseModel : The original model to train. This can be one of the models in our supported models shown at the bottom of this page deploy : Weather training weights should be hosted in a hosting service. Default False. deployToHf : Whether traiing weights should be stored in huggingface specifically. Either true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model inputValue : The input value to extract from the data retrieved, default: 'input' outputValue : The output value to extract from the data retrieved, default: 'output' CLI args are parsed as YAML when running commands. this is a non-exhaustive list of valid operations langdrive train langdrive train --yaml \"../pathToYaml.yaml\" langdrive train --hfToken 1234 --csv \"../shared.csv\" langdrive train --hfToken 1234 --csv ../shared.csv --inputValue \"inputColname\" --outputValue \"colname\" langdrive train --csv \"./tests/midjourney_prompt.csv\" --deploy","title":"CLI"},{"location":"cli/#command-line-interface","text":"Simply: Install Langdrive: npm isntall langdrive Train a model: `langdrive train` + [...Args]` Here are your Args: yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training data. The training data should be a two-column CSV of input and output pairs. hfToken : An API key provided by Hugging Face with write permissions. Get one here . baseModel : The original model to train. This can be one of the models in our supported models shown at the bottom of this page deploy : Weather training weights should be hosted in a hosting service. Default False. deployToHf : Whether traiing weights should be stored in huggingface specifically. Either true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model inputValue : The input value to extract from the data retrieved, default: 'input' outputValue : The output value to extract from the data retrieved, default: 'output' CLI args are parsed as YAML when running commands. this is a non-exhaustive list of valid operations langdrive train langdrive train --yaml \"../pathToYaml.yaml\" langdrive train --hfToken 1234 --csv \"../shared.csv\" langdrive train --hfToken 1234 --csv ../shared.csv --inputValue \"inputColname\" --outputValue \"colname\" langdrive train --csv \"./tests/midjourney_prompt.csv\" --deploy","title":"Command Line Interface"},{"location":"contributors/","text":"Contributing Thank you for the interest! We would love to see a PR! At the moment the CLI only supports the deploy command: main.js #!/usr/bin/env node if (process.argv.length >= 3 && process.argv[2] === 'deploy') { console.log('test'); } To help with your development, these command may help: npm link --loglevel verbose - Uses loads the current repo and a npm module. npm unlink langdrive - Unlink for good measure npm unlink langdrive, npm link --loglevel verbose - Do both Docs Two bash scripts exist to help with the development of our docs. pip install mkdocs - Installs mkdocs npm run serveDocs - Serves .md files from ./docs using mkdocs' dev server npm run buildDocs - Builds the site using ./docs' for use in github pages","title":"Contributors"},{"location":"contributors/#contributing","text":"Thank you for the interest! We would love to see a PR! At the moment the CLI only supports the deploy command: main.js #!/usr/bin/env node if (process.argv.length >= 3 && process.argv[2] === 'deploy') { console.log('test'); } To help with your development, these command may help: npm link --loglevel verbose - Uses loads the current repo and a npm module. npm unlink langdrive - Unlink for good measure npm unlink langdrive, npm link --loglevel verbose - Do both","title":"Contributing"},{"location":"contributors/#docs","text":"Two bash scripts exist to help with the development of our docs. pip install mkdocs - Installs mkdocs npm run serveDocs - Serves .md files from ./docs using mkdocs' dev server npm run buildDocs - Builds the site using ./docs' for use in github pages","title":"Docs"},{"location":"demo/","text":"Demo Create a chatbot using Google Drive. Make it smart and store data by connecting it to you or your visitors' google drive account. Select your AI Model and optionally connect you and/or your users' google drive. 1 CLICK DEPLOY Get a chatbot up and running NOW ! Click here to Set Heroku Secret Variables to gain access to their service GOOGLE_WEB_CLIENT_ID and GOOGLE_WEB_CLIENT_SECRET with Google OAuth2 Keys instructions are needed for user login and to connect Google Drive to their chatbot. OPENAI_API_KEY for ChatGPT4. HUGGINGFACE_API_KEY to use a HuggingFace LLM. App Developers You can clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start More instructions for hands-on configuration available in the Chatbot section","title":"Demo"},{"location":"demo/#demo","text":"Create a chatbot using Google Drive. Make it smart and store data by connecting it to you or your visitors' google drive account. Select your AI Model and optionally connect you and/or your users' google drive.","title":"Demo"},{"location":"demo/#1-click-deploy","text":"Get a chatbot up and running NOW ! Click here to Set Heroku Secret Variables to gain access to their service GOOGLE_WEB_CLIENT_ID and GOOGLE_WEB_CLIENT_SECRET with Google OAuth2 Keys instructions are needed for user login and to connect Google Drive to their chatbot. OPENAI_API_KEY for ChatGPT4. HUGGINGFACE_API_KEY to use a HuggingFace LLM.","title":"1 CLICK DEPLOY"},{"location":"demo/#app-developers","text":"You can clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start More instructions for hands-on configuration available in the Chatbot section","title":"App Developers"},{"location":"gettingStarted/","text":"Getting Started Thank you for taking interest in LangDrive! Langdrive's set of connectors and services makes training LLMs easy, and you can get started with just a CSV file! By providing a Hugging Face API key you can even train models and host them directly in the cloud \ud83d\ude09 Import Langdrive in your project or configure and execute Langdrive directly from the CLI. The remainder of this article will explore using both approaches for training and deploy models with langdrive. Along the way we will explore the use of a YAML doc to help with the connecting to data and services. Using the CLI Node developers can train and deploy a model in 2 simple steps. npm install langdrive langdrive train --csv ./path/to/csvFileName.csv --hftoken apikey123 --deploy In this case, Langdrive will retrieve the data, train a model, host it's weights on Hugging Face, and return an inference endpoint you may use to query the LLM. The command langdrive train is used to train the LLM, please see how to configure the command below. CLI Arguements : yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training data. The training data should be a two-column CSV of input and output pairs. hfToken : An API key provided by Hugging Face with write permissions. Get one here . baseModel : The original model to train. This can be one of the models in our supported models shown at the bottom of this page deploy : Weather training weights should be hosted in a hosting service. Default False. deployToHf : Whether traiing weights should be stored in huggingface specifically. Either true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model It is assumed you do not want to deploy your model if you run langdrive train . In such a case a link to where you can download the weights will be provided. Adding --deployToHf will return a link to the inferencing endpoint. More information on how to ingest simple data using the CLI can be found in the CLI docs. For more complex examples, read on... Getting Started with YAML Getting the data and services you need shouldn't be the hardest part about training your models! Using YAML, you can configure more advanced data retrieval, processing, and training/ deployment strategies. Once configured, these settings are available for the standalone API and also from the CLI. Refer to the Yaml docs for more information. Step 1: Configure Your Data Connectors Our growing list of data-connectors allow anyone to retrieve data through a simple config doc. As LangDrive grows, our set of Open-Source integrations will grow. At the moment, you can connect to your data using our email , firestore , and gdrive classes. In essense, config of these data-connectors is as straight forward as: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: appType: \"desktop\" clientJson: \"secrets/drive_service_client.json\" scopes: - \"https://www.googleapis.com/auth/drive\" - \"https://www.googleapis.com/auth/drive.metadata.readonly\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL You may specify .env variables using env: as a prefix for your secret information. In our example above, the clientJson attribute is a Firebase service account file . Once this information is provided, the entire OAuth Process will automatically be handled on your behalf when using any associated library, regardless if it's used in the CLI or API. Please refer to our notes on security for more information on the Outh2 process when using google. Step 2: Configure Your LLM Tools Once you have your data-connectors set up, config your training and deployment information. The last step will be to connect the two. Training on Hugging Face and hosting the weights on Hugging Face hubs: huggingface: hfToken: env:HUGGINGFACE_API_KEY deployToHf: false NOTE : To specify the model you want to train and where to host it: huggingface: hfToken: env:HUGGINGFACE_API_KEY baseModel: vilsonrodrigues/falcon-7b-instruct-sharded trainedModel: karpathic/falcon-7b-instruct-tuned deployToHf: true Simple enough, huh? Here comes the final step. Step 3: Connecting Your Data to Your LLM To connect data to your LLM tool, we will need to create a new YAML entry train: . Here we specify specific the specific data we want to train on. In the case of a CSV, a most simple example, we can use the path value to specify it's location. langdrive.yaml train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Now lets show how to query data from one of those third-party services we configured earlier. Setting a service and query within the train entry will do this. To begin, set the name of a data-connector as the service and one of its methods (and its args) as the query value. Users are encouraged to explore the service documentation to find available methods and the parameters they take. Once the service, method, and parameters are known - you may set them like so: langdrive.yaml train: service: 'firestore' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 In the example above we use the filterCollectionWithMultipleWhereClauseWithLimit method from Langdrive's Firestore class, passing arguements as specified in the Langdrive Firestore docs. collection is the firestore collection name to retrieve data from, (limited to the first 5 entries). filterKey and filterData are not specified in this example but contain the field name/key to filter. The operation value specifies the firebstore query operator to use (For example, '==', '>=', '<=' ). Note : If the retrieved data has two columns (or attributes) they are assumed to be in the order [input, output]. If more columns exist, langdrive grabs the first two columns after first looking for an 'inputValue' and 'outpuValue' column. The same logic applies for information retrieved from a query and works similarly for nested Json Objects (ala: att1.attr2 ) Gettings Started with API: Our classes can be exposed in the typical manner. For more information on any one class, please refer to it's corresponding documentation. Coming Soon: Deploy self-hosted cloud based training infrastructure on AWS, Google Cloud Platform, Heroku, or Hugging Face. Code is currently being used internally and is under development prior to general release - code avaialbe in-repo under /src/train . If you would like to interact directly directly with our training endpoint you can call our hosted training image directly via the langdrive API. Endpoint: POST https://api.langdrive.ai/train You can test the quality of one of these models by visit the Langdrive Playground Request Body The request accepts the following data in JSON format. { \"baseModel\": \"string\", \"hfToken\": \"string\", \"deployToHf\": \"Boolean\", \"trainingData\": \"Array\", \"hfModelPath\": \"string\", } baseModel : The original model to train. This can be one of our supported models, listed below, or a Hugging Face model Type: String Required: Yes hfToken : Your Hugging Face token with write permissions. Learn how to create a Hugging Face token here . Type: String Required: Yes deployToHf : A boolean representing whether or not to deploy the model to Hugging Face after training Type: Boolean Required: Yes trainingData : This is an array of objects. Each object must have two attributes: input and output. The input attribute represents the user\u2019s input and output attribute represents the model\u2019s output. Type: Array Required: Yes hfModelPath : The hugging face model repository to deploy the model to after training is complete. This path must exist before being used Type: String Required: No Response Body The request returns the following data in JSON format. HTTP/1.1 200 Content-type: application/json { \"success\": \"true\", } Model Training We plan to expand the number of available models for training. at the moment only sharded models work as using PEFT is how these models are trained. Models Support Matrix Causal Language Modeling Model Supported Falcon-7b-sharded \u2705 GPT-2 Comming Soon Bloom Comming Soon OPT Comming Soon LLaMA Comming Soon ChatGLM Comming Soon Model Type Support Model Type Support Conditional Generation \u2705 Conditional Generation \u2705 Sequence Classification \u2705 Token Classification \u2705 Text-to-Image Generation Image Classification Image to text (Multi-modal models) Semantic Segmentation","title":"Getting Started"},{"location":"gettingStarted/#getting-started","text":"Thank you for taking interest in LangDrive! Langdrive's set of connectors and services makes training LLMs easy, and you can get started with just a CSV file! By providing a Hugging Face API key you can even train models and host them directly in the cloud \ud83d\ude09 Import Langdrive in your project or configure and execute Langdrive directly from the CLI. The remainder of this article will explore using both approaches for training and deploy models with langdrive. Along the way we will explore the use of a YAML doc to help with the connecting to data and services.","title":"Getting Started"},{"location":"gettingStarted/#using-the-cli","text":"Node developers can train and deploy a model in 2 simple steps. npm install langdrive langdrive train --csv ./path/to/csvFileName.csv --hftoken apikey123 --deploy In this case, Langdrive will retrieve the data, train a model, host it's weights on Hugging Face, and return an inference endpoint you may use to query the LLM. The command langdrive train is used to train the LLM, please see how to configure the command below. CLI Arguements : yaml : Path to optional YAML config doc, default Value: './langdrive.yaml'. This will load up any class and query for records and their values for both inputs and ouputs. csv : Path to training data. The training data should be a two-column CSV of input and output pairs. hfToken : An API key provided by Hugging Face with write permissions. Get one here . baseModel : The original model to train. This can be one of the models in our supported models shown at the bottom of this page deploy : Weather training weights should be hosted in a hosting service. Default False. deployToHf : Whether traiing weights should be stored in huggingface specifically. Either true | false hfModelPath : The full path to your hugging face model repo where the model should be deployed. Format: hugging face username/model It is assumed you do not want to deploy your model if you run langdrive train . In such a case a link to where you can download the weights will be provided. Adding --deployToHf will return a link to the inferencing endpoint. More information on how to ingest simple data using the CLI can be found in the CLI docs. For more complex examples, read on...","title":"Using the CLI"},{"location":"gettingStarted/#getting-started-with-yaml","text":"Getting the data and services you need shouldn't be the hardest part about training your models! Using YAML, you can configure more advanced data retrieval, processing, and training/ deployment strategies. Once configured, these settings are available for the standalone API and also from the CLI. Refer to the Yaml docs for more information.","title":"Getting Started with YAML"},{"location":"gettingStarted/#step-1-configure-your-data-connectors","text":"Our growing list of data-connectors allow anyone to retrieve data through a simple config doc. As LangDrive grows, our set of Open-Source integrations will grow. At the moment, you can connect to your data using our email , firestore , and gdrive classes. In essense, config of these data-connectors is as straight forward as: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: appType: \"desktop\" clientJson: \"secrets/drive_service_client.json\" scopes: - \"https://www.googleapis.com/auth/drive\" - \"https://www.googleapis.com/auth/drive.metadata.readonly\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL You may specify .env variables using env: as a prefix for your secret information. In our example above, the clientJson attribute is a Firebase service account file . Once this information is provided, the entire OAuth Process will automatically be handled on your behalf when using any associated library, regardless if it's used in the CLI or API. Please refer to our notes on security for more information on the Outh2 process when using google.","title":"Step 1: Configure Your Data Connectors"},{"location":"gettingStarted/#step-2-configure-your-llm-tools","text":"Once you have your data-connectors set up, config your training and deployment information. The last step will be to connect the two. Training on Hugging Face and hosting the weights on Hugging Face hubs: huggingface: hfToken: env:HUGGINGFACE_API_KEY deployToHf: false NOTE : To specify the model you want to train and where to host it: huggingface: hfToken: env:HUGGINGFACE_API_KEY baseModel: vilsonrodrigues/falcon-7b-instruct-sharded trainedModel: karpathic/falcon-7b-instruct-tuned deployToHf: true Simple enough, huh? Here comes the final step.","title":"Step 2: Configure Your LLM Tools"},{"location":"gettingStarted/#step-3-connecting-your-data-to-your-llm","text":"To connect data to your LLM tool, we will need to create a new YAML entry train: . Here we specify specific the specific data we want to train on. In the case of a CSV, a most simple example, we can use the path value to specify it's location. langdrive.yaml train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Now lets show how to query data from one of those third-party services we configured earlier. Setting a service and query within the train entry will do this. To begin, set the name of a data-connector as the service and one of its methods (and its args) as the query value. Users are encouraged to explore the service documentation to find available methods and the parameters they take. Once the service, method, and parameters are known - you may set them like so: langdrive.yaml train: service: 'firestore' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 In the example above we use the filterCollectionWithMultipleWhereClauseWithLimit method from Langdrive's Firestore class, passing arguements as specified in the Langdrive Firestore docs. collection is the firestore collection name to retrieve data from, (limited to the first 5 entries). filterKey and filterData are not specified in this example but contain the field name/key to filter. The operation value specifies the firebstore query operator to use (For example, '==', '>=', '<=' ). Note : If the retrieved data has two columns (or attributes) they are assumed to be in the order [input, output]. If more columns exist, langdrive grabs the first two columns after first looking for an 'inputValue' and 'outpuValue' column. The same logic applies for information retrieved from a query and works similarly for nested Json Objects (ala: att1.attr2 )","title":"Step 3: Connecting Your Data to Your LLM"},{"location":"gettingStarted/#gettings-started-with-api","text":"Our classes can be exposed in the typical manner. For more information on any one class, please refer to it's corresponding documentation. Coming Soon: Deploy self-hosted cloud based training infrastructure on AWS, Google Cloud Platform, Heroku, or Hugging Face. Code is currently being used internally and is under development prior to general release - code avaialbe in-repo under /src/train . If you would like to interact directly directly with our training endpoint you can call our hosted training image directly via the langdrive API. Endpoint: POST https://api.langdrive.ai/train You can test the quality of one of these models by visit the Langdrive Playground","title":"Gettings Started with API:"},{"location":"gettingStarted/#request-body","text":"The request accepts the following data in JSON format. { \"baseModel\": \"string\", \"hfToken\": \"string\", \"deployToHf\": \"Boolean\", \"trainingData\": \"Array\", \"hfModelPath\": \"string\", } baseModel : The original model to train. This can be one of our supported models, listed below, or a Hugging Face model Type: String Required: Yes hfToken : Your Hugging Face token with write permissions. Learn how to create a Hugging Face token here . Type: String Required: Yes deployToHf : A boolean representing whether or not to deploy the model to Hugging Face after training Type: Boolean Required: Yes trainingData : This is an array of objects. Each object must have two attributes: input and output. The input attribute represents the user\u2019s input and output attribute represents the model\u2019s output. Type: Array Required: Yes hfModelPath : The hugging face model repository to deploy the model to after training is complete. This path must exist before being used Type: String Required: No","title":"Request Body"},{"location":"gettingStarted/#response-body","text":"The request returns the following data in JSON format. HTTP/1.1 200 Content-type: application/json { \"success\": \"true\", }","title":"Response Body"},{"location":"gettingStarted/#model-training","text":"We plan to expand the number of available models for training. at the moment only sharded models work as using PEFT is how these models are trained.","title":"Model Training"},{"location":"gettingStarted/#models-support-matrix","text":"","title":"Models Support Matrix"},{"location":"gettingStarted/#causal-language-modeling","text":"Model Supported Falcon-7b-sharded \u2705 GPT-2 Comming Soon Bloom Comming Soon OPT Comming Soon LLaMA Comming Soon ChatGLM Comming Soon","title":"Causal Language Modeling"},{"location":"gettingStarted/#model-type-support","text":"Model Type Support Conditional Generation \u2705 Conditional Generation \u2705 Sequence Classification \u2705 Token Classification \u2705 Text-to-Image Generation Image Classification Image to text (Multi-modal models) Semantic Segmentation","title":"Model Type Support"},{"location":"yaml/","text":"There are many ways to configure your YAML doc to support maximal flexibility. The basis of your YAML doc will most typically have a train object along with any other classes you want to configure The Classes being configured like: firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: clientJson: \"secrets/drive_service_client.json\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL huggingface: token: env:HUGGINGFACE_API_KEY note : CLI based commands will retrieve the YAML doc and merge any args into the root of the yaml doc and processed accordingly. Example 0: Bespoke example with many settings ``` verbose: true firestore: clientJson: \"secrets/firebase_service_client.json\" databaseURL: \"env:FIREBASE_DATABASE_URL\" drive: appType: \"desktop\" clientJson: \"secrets/drive_service_client.json\" scopes: - \"https://www.googleapis.com/auth/drive\" - \"https://www.googleapis.com/auth/drive.metadata.readonly\" email: password: env:GMAIL_PASSWORD email: env:GMAIL_EMAIL huggingface: hfToken: env:HUGGINGFACE_API_KEY baseModel: vilsonrodrigues/falcon-7b-instruct-sharded trainedModel: karpathic/falcon-7b-instruct-tuned deployToHf: true train: service: firestore query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [\"type\"] filterData: [\"customer-inquiry-bot\"] operation: [\"==\"] limit: 5 input: value: \"chat.0.content\" output: value: \"chat.1.content\" ``` Example 1: Training on a CSV with two columns (or an input and output column). train: path: ../shared.csv Example 2: Specify Input and Output values in a CSV train: path: ../shared.csv - Default Path for Input and Output inputValue: input - Attribute to extract from path outpuValue: output Example 3: Attribute to extract from path train: inputPath: ../input.csv outputPath: ../output.csv inputValue: input outpuValue: output Example 4: Attribute to extraxt path using input and output objects train: input: path: ../input.csv value: colname output: path: ../output.csv value: colname Example 5: Specifying default path for Input and Output train: path: ../shared.csv input: value: colname output: value: colname Querying for data from a service is denoted by the query attribute placed. This may be placed as a base object, or nested within a 'input' or 'output' object. The query value follows the schema train: service: 'serviceName' query: serviceMethodName : {methodParameters} Here's an example: train: service: 'firestore' query: filterCollectionWithMultipleWhereClauseWithLimit: collection: \"chat-state\" filterKey: [] filterData: [] operation: [] limit: 5 input: value: \"chat.0.content\" output: value: \"chat.1.content\" train: service: 'gdrive' query: getFileByName: filename: 'test123' mimeType: 'application/msword' directory: false directoryId: false input: value: \"input\" output: value: \"output\" To specify the model you want to train and where to host it: huggingface: hfToken: env:HUGGINGFACE_API_KEY baseModel: vilsonrodrigues/falcon-7b-instruct-sharded trainedModel: karpathic/falcon-7b-instruct-tuned deployToHf: true","title":"Yaml"},{"location":"api/chatbot/","text":"NPM: Langdrive: DriveChatbot Class The Chatbot returns Async Promises. Chatbot's minimal initalization is like so: chatbot = new langdrive.DriveChatbot({model_config:{HuggingFaceAPIKey:<KEY>}}) or like so: chatbot = new langdrive.Chatbot({model_config:{openAIApiKey:<KEY>}}) Chatbot Example Script Get started with a sample script by created the following files: npm install langdrive dotenv node test.js .env File: OPENAI_API_KEY=<YOUR_KEY_HERE> GOOGLE_DESKTOP_CLIENT_KEYFILE_PATH=<YOUR_KEY_HERE> test.js File: require(\"dotenv\").config(); const langdrive = require(\"langdrive\"); // LangDrive returns promises (async()=>{ // To initialize Langdrive, give it a model to use and any associated config information. // Here we select openAi and pass it an API key (hidden behind .env) let chatbot = await new langdrive.DriveChatbot({ verbose: true, drive: { verbose: false, ...(!GOOGLE_DESKTOP_KEYFILE_PATH ? {} : { server: { embed_from_folder: \"chatbot\", embed_to_folder: \"chatbot/embeddings\", scopes: [\"https://www.googleapis.com/auth/drive\"], // serviceKeyFile: __dirname + \"/../\" + GOOGLE_SERVICE_KEYFILE_PATH // OR desktopKeyFile: __dirname + GOOGLE_DESKTOP_KEYFILE_PATH // ( Alternately:) desktopKeyFileContents: GOOGLE_DESKTOP_CLIENT_KEYFILE_CONTENTS // OR // desktopTokenFile: GOOGLE_DESKTOP_CLIENT_TOKEN_PATH: // ( Alternately:) desktopTokenFileContents: GOOGLE_DESKTOP_CLIENT_TOKEN_CONTENTS // OR //client_id: GOOGLE_DESKTOP_CLIENT_ID, // and //client_secret: GOOGLE_SERVICE_CLIENT_SECRET //and //client_redirect_uri: xyz } }) }, model: { service: !!HUGGINGFACE_API_KEY ? \"huggingFace\" : \"chatOpenAi\", model_config: !!HUGGINGFACE_API_KEY ? { model_id: \"meta-llama/Llama-2-30b\", huggingFaceApiKey: HUGGINGFACE_API_KEY } : { modelName: \"gpt-3.5-turbo\", // default = \"text-davinci-003\" // maxTokens: 256, // default = 256 openAIApiKey: OPENAI_API_KEY, temperature: 0.9 } }, agent: { type: \"chat-conversational-react-description\", memory_length: 2, vector_length: 2, verbose: false, tools: [], agent_config: {} // prefix // suffix } }); // LangDrive returns a promise, so let's await those. let prompt = \"My name is Michael, What can you do for me.\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What can you do for me in google drive?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What is my name?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); })() You can also clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start Chatbot Properties The props used in DriveChatbot( props ) configure your chatbot. Available settings and their default values are shown below.","title":"Chatbot"},{"location":"api/chatbot/#npm-langdrive-drivechatbot-class","text":"The Chatbot returns Async Promises. Chatbot's minimal initalization is like so: chatbot = new langdrive.DriveChatbot({model_config:{HuggingFaceAPIKey:<KEY>}}) or like so: chatbot = new langdrive.Chatbot({model_config:{openAIApiKey:<KEY>}})","title":"NPM: Langdrive: DriveChatbot Class"},{"location":"api/chatbot/#chatbot-example-script","text":"Get started with a sample script by created the following files: npm install langdrive dotenv node test.js .env File: OPENAI_API_KEY=<YOUR_KEY_HERE> GOOGLE_DESKTOP_CLIENT_KEYFILE_PATH=<YOUR_KEY_HERE> test.js File: require(\"dotenv\").config(); const langdrive = require(\"langdrive\"); // LangDrive returns promises (async()=>{ // To initialize Langdrive, give it a model to use and any associated config information. // Here we select openAi and pass it an API key (hidden behind .env) let chatbot = await new langdrive.DriveChatbot({ verbose: true, drive: { verbose: false, ...(!GOOGLE_DESKTOP_KEYFILE_PATH ? {} : { server: { embed_from_folder: \"chatbot\", embed_to_folder: \"chatbot/embeddings\", scopes: [\"https://www.googleapis.com/auth/drive\"], // serviceKeyFile: __dirname + \"/../\" + GOOGLE_SERVICE_KEYFILE_PATH // OR desktopKeyFile: __dirname + GOOGLE_DESKTOP_KEYFILE_PATH // ( Alternately:) desktopKeyFileContents: GOOGLE_DESKTOP_CLIENT_KEYFILE_CONTENTS // OR // desktopTokenFile: GOOGLE_DESKTOP_CLIENT_TOKEN_PATH: // ( Alternately:) desktopTokenFileContents: GOOGLE_DESKTOP_CLIENT_TOKEN_CONTENTS // OR //client_id: GOOGLE_DESKTOP_CLIENT_ID, // and //client_secret: GOOGLE_SERVICE_CLIENT_SECRET //and //client_redirect_uri: xyz } }) }, model: { service: !!HUGGINGFACE_API_KEY ? \"huggingFace\" : \"chatOpenAi\", model_config: !!HUGGINGFACE_API_KEY ? { model_id: \"meta-llama/Llama-2-30b\", huggingFaceApiKey: HUGGINGFACE_API_KEY } : { modelName: \"gpt-3.5-turbo\", // default = \"text-davinci-003\" // maxTokens: 256, // default = 256 openAIApiKey: OPENAI_API_KEY, temperature: 0.9 } }, agent: { type: \"chat-conversational-react-description\", memory_length: 2, vector_length: 2, verbose: false, tools: [], agent_config: {} // prefix // suffix } }); // LangDrive returns a promise, so let's await those. let prompt = \"My name is Michael, What can you do for me.\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What can you do for me in google drive?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); prompt = \"What is my name?\"; console.log(\"> \" , await chatbot.sendMessage(prompt)); })() You can also clone the repo and get started with our demo chatbot Download Repo npm install Create Google OAuth2 Keys .env.examples -> .env + Keys npm run start","title":"Chatbot Example Script"},{"location":"api/chatbot/#chatbot-properties","text":"The props used in DriveChatbot( props ) configure your chatbot. Available settings and their default values are shown below.","title":"Chatbot Properties"},{"location":"api/dataOverview/","text":"Data Connectors Overview Welcome to the Data Connectors Overview! This document offers a detailed guide on the functionalities and capabilities of several Node.js classes, designed to enhance your development experience. Firestore Class Overview Class: Firestore The Firestore class in Node.js is designed for robust interaction with Firebase Firestore. It supports various operations like querying, adding, updating, and deleting documents in your Firestore database. Constructor Parameters : props (Object): Contains the Firestore database instance. Description : Initializes the Firestore class with a database instance. Key Methods filterCollectionWithWhereClause(...) : Filters a collection using a where clause. addDocumentToCollection(...) : Adds a new document to a specified collection. updateDocument(...) : Updates an existing document in a collection. deleteDocumentFromCollection(...) : Deletes a document from a collection. getAllDocumentsInCollection(...) : Retrieves all documents from a specified collection. EmailRetriever Class Overview Class: EmailRetriever The EmailRetriever class in Node.js is tailored for retrieving emails from different email clients using SMTP configurations. It provides a streamlined approach to email retrieval. Constructor Parameters : emailAddress (String): The email account's address. emailPassword (String): The email account's password. emailClient (String): The email client hosting the account. verbose (Boolean): Enables verbose error logging. Description : Initializes the EmailRetriever with email credentials and client. Key Methods getEmailsInFolder(...) : Retrieves emails from a specific folder in the email account. validateSMTPConfig() : Validates the SMTP configuration for the email client. Additional Information SMTP Configuration : Uses predefined SMTP settings for supported email clients. Error Handling : Robust error management, especially for unsupported email clients. External API Integration : Utilizes external APIs for email retrieval. DriveUtils Class: DriveUtils The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs. Constructor Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web). Key Methods getDrive() : Initializes and retrieves the Google Drive instance. listFiles(props) : Lists files in Google Drive based on properties like directory, mime type, etc. listDirectories(props) : Lists all directories or directories within a specific directory. getFileInfo(props) : Retrieves information about a specific file based on provided criteria. getFileById(props) : Retrieves a file by its ID. getFileByName(props) : Retrieves a file by its name. createFile(props) : Creates a file in Google Drive. createAndOrGetContent(props) : Creates or retrieves content based on a given path and other criteria. updateFile(props) : Updates a file in Google Drive. Static Methods getAuthUrl(config) : Generates a Google authentication URL for obtaining access tokens. handleAuthCallback(config) : Handles the authentication callback from Google to get access tokens. checkAndRefresh(config) : Checks and refreshes the access token if it is expired. refreshToken(config) : Refreshes the access token. Comments and Additional Information The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to","title":"Overview"},{"location":"api/dataOverview/#data-connectors-overview","text":"Welcome to the Data Connectors Overview! This document offers a detailed guide on the functionalities and capabilities of several Node.js classes, designed to enhance your development experience.","title":"Data Connectors Overview"},{"location":"api/dataOverview/#firestore-class-overview","text":"","title":"Firestore Class Overview"},{"location":"api/dataOverview/#class-firestore","text":"The Firestore class in Node.js is designed for robust interaction with Firebase Firestore. It supports various operations like querying, adding, updating, and deleting documents in your Firestore database.","title":"Class: Firestore"},{"location":"api/dataOverview/#constructor","text":"Parameters : props (Object): Contains the Firestore database instance. Description : Initializes the Firestore class with a database instance.","title":"Constructor"},{"location":"api/dataOverview/#key-methods","text":"filterCollectionWithWhereClause(...) : Filters a collection using a where clause. addDocumentToCollection(...) : Adds a new document to a specified collection. updateDocument(...) : Updates an existing document in a collection. deleteDocumentFromCollection(...) : Deletes a document from a collection. getAllDocumentsInCollection(...) : Retrieves all documents from a specified collection.","title":"Key Methods"},{"location":"api/dataOverview/#emailretriever-class-overview","text":"","title":"EmailRetriever Class Overview"},{"location":"api/dataOverview/#class-emailretriever","text":"The EmailRetriever class in Node.js is tailored for retrieving emails from different email clients using SMTP configurations. It provides a streamlined approach to email retrieval.","title":"Class: EmailRetriever"},{"location":"api/dataOverview/#constructor_1","text":"Parameters : emailAddress (String): The email account's address. emailPassword (String): The email account's password. emailClient (String): The email client hosting the account. verbose (Boolean): Enables verbose error logging. Description : Initializes the EmailRetriever with email credentials and client.","title":"Constructor"},{"location":"api/dataOverview/#key-methods_1","text":"getEmailsInFolder(...) : Retrieves emails from a specific folder in the email account. validateSMTPConfig() : Validates the SMTP configuration for the email client.","title":"Key Methods"},{"location":"api/dataOverview/#additional-information","text":"SMTP Configuration : Uses predefined SMTP settings for supported email clients. Error Handling : Robust error management, especially for unsupported email clients. External API Integration : Utilizes external APIs for email retrieval.","title":"Additional Information"},{"location":"api/dataOverview/#driveutils","text":"","title":"DriveUtils"},{"location":"api/dataOverview/#class-driveutils","text":"The DriveUtils class in Node.js is designed to interface with Google Drive. It handles authentication, file listing, information retrieval, and file operations using Google APIs.","title":"Class: DriveUtils"},{"location":"api/dataOverview/#constructor_2","text":"Parameters : props (Object) containing various configuration options. Description : Initializes the class with properties such as client_id , client_secret , scopes , and keyFilePath . Handles authentication for different application types (server, desktop, web).","title":"Constructor"},{"location":"api/dataOverview/#key-methods_2","text":"getDrive() : Initializes and retrieves the Google Drive instance. listFiles(props) : Lists files in Google Drive based on properties like directory, mime type, etc. listDirectories(props) : Lists all directories or directories within a specific directory. getFileInfo(props) : Retrieves information about a specific file based on provided criteria. getFileById(props) : Retrieves a file by its ID. getFileByName(props) : Retrieves a file by its name. createFile(props) : Creates a file in Google Drive. createAndOrGetContent(props) : Creates or retrieves content based on a given path and other criteria. updateFile(props) : Updates a file in Google Drive.","title":"Key Methods"},{"location":"api/dataOverview/#static-methods","text":"getAuthUrl(config) : Generates a Google authentication URL for obtaining access tokens. handleAuthCallback(config) : Handles the authentication callback from Google to get access tokens. checkAndRefresh(config) : Checks and refreshes the access token if it is expired. refreshToken(config) : Refreshes the access token.","title":"Static Methods"},{"location":"api/dataOverview/#comments-and-additional-information","text":"The class provides various static and instance methods for handling Google Drive operations. It supports different types of applications like server, desktop, and web. The methods are comprehensive, covering from authentication to","title":"Comments and Additional Information"},{"location":"api/email/","text":"EmailRetriever Documentation Description : The EmailRetriever class is designed to fetch emails from specific folders within an email account. It supports multiple email clients and allows for easy email retrieval with support for IMAP search commands. It leverages proprietary Addy AI technology to interact with email servers and facilitates the extraction of email data for use in applications. Constructor: EmailRetriever() Returns : An instance of the EmailRetriever class. Description : Initializes an EmailRetriever instance with the provided details for email access and retrieval. Throws an error if the specified email client is not supported. Example : Instantiate the EmailRetriever for a Gmail account with verbose error logging. const retriever = new EmailRetriever( 'your-email@gmail.com', 'your-password', 'gmail', true ); Parameters : Parameter Name Description Accepted Values/Data Types emailAddress The email address of the account to initialize String emailPassword The password of the email account String emailClient The email client hosting the email address \"gmail\" | \"outlook\" verbose Indicates if errors should be printed out Boolean Method: getEmailsInFolder() Returns : A promise that resolves to an array of emails upon successful retrieval or undefined if unsuccessful. Description : Fetches emails from a specified folder within the user's email account up to a specified limit. If verbose is true , any errors encountered will be printed to the console. Example : Retrieve the last 10 unseen emails in the Inbox folder. retriever.getEmailsInFolder('Inbox', '10', 'UNSEEN') .then(emails => { if (emails) { console.log('Retrieved Emails:', emails); } else { console.log('No emails fetched or an error occurred'); } }) .catch(error => console.error(error)); Parameters : Parameter Name Description Accepted Values/Data Types folderName The name of the folder to scan for emails String limit The maximum number of emails to retrieve String IMAPSearchCommand The IMAP command to determine which emails to fetch \"ALL\" | \"UNSEEN\" | \"SEEN\"","title":"Email"},{"location":"api/email/#emailretriever-documentation","text":"Description : The EmailRetriever class is designed to fetch emails from specific folders within an email account. It supports multiple email clients and allows for easy email retrieval with support for IMAP search commands. It leverages proprietary Addy AI technology to interact with email servers and facilitates the extraction of email data for use in applications.","title":"EmailRetriever Documentation"},{"location":"api/email/#constructor-emailretriever","text":"Returns : An instance of the EmailRetriever class. Description : Initializes an EmailRetriever instance with the provided details for email access and retrieval. Throws an error if the specified email client is not supported. Example : Instantiate the EmailRetriever for a Gmail account with verbose error logging. const retriever = new EmailRetriever( 'your-email@gmail.com', 'your-password', 'gmail', true ); Parameters : Parameter Name Description Accepted Values/Data Types emailAddress The email address of the account to initialize String emailPassword The password of the email account String emailClient The email client hosting the email address \"gmail\" | \"outlook\" verbose Indicates if errors should be printed out Boolean","title":"Constructor: EmailRetriever()"},{"location":"api/email/#method-getemailsinfolder","text":"Returns : A promise that resolves to an array of emails upon successful retrieval or undefined if unsuccessful. Description : Fetches emails from a specified folder within the user's email account up to a specified limit. If verbose is true , any errors encountered will be printed to the console. Example : Retrieve the last 10 unseen emails in the Inbox folder. retriever.getEmailsInFolder('Inbox', '10', 'UNSEEN') .then(emails => { if (emails) { console.log('Retrieved Emails:', emails); } else { console.log('No emails fetched or an error occurred'); } }) .catch(error => console.error(error)); Parameters : Parameter Name Description Accepted Values/Data Types folderName The name of the folder to scan for emails String limit The maximum number of emails to retrieve String IMAPSearchCommand The IMAP command to determine which emails to fetch \"ALL\" | \"UNSEEN\" | \"SEEN\"","title":"Method: getEmailsInFolder()"},{"location":"api/firestore/","text":"Firestore Documentation Description : The Firestore class provides a variety of methods to interact with documents and collections in Firebase Firestore. It allows you to filter, add, create, update, and delete documents in Firestore collections, including subcollections. For each method follow this structure: Method: filterCollectionWithWhereClause(collection, filterKey, filterData, operation) Returns : An array of documents that match the provided filters. Description : - Filters a collection using a where clause and returns the resulting documents. - Throws an error if there is an issue retrieving the documents. Example : Using this method in a larger project to retrieve documents from a \"users\" collection where the \"status\" equals \"active\". const userDocs = await firestoreInstance.filterCollectionWithWhereClause( \"users\", \"status\", \"active\", \"==\" ); Parameters : Parameter Name Description Accepted Values/Data Types collection The name of the collection to be filtered. String filterKey The key/field name to filter by. String filterData The value to match for the given filterKey. String operation The Firestore query operator. String (Firestore query operators) Method: addDocumentToCollection(document, collection) Returns : An object containing the success status and the ID of the document added. Description : - Adds a new document to the specified collection. - If an error occurs, it throws an exception with the error details. Example : Adding a new user object to the \"users\" collection in Firestore. const addResult = await firestoreInstance.addDocumentToCollection(newUser, \"users\"); if (addResult.success) { console.log(`Added document with ID: ${addResult.docID}`); } Parameters : Parameter Name Description Accepted Values/Data Types document The data object of the document. Object collection The name of the target collection. String (Note: The documentation template above is applied to only the filterCollectionWithWhereClause method and addDocumentToCollection . Similar formatting would follow for each method defined within the Firestore class itself, but due to the length and number of methods, not all methods have been templated here. Each method should get its own section following the given structure.)","title":"Firestore"},{"location":"api/firestore/#firestore-documentation","text":"Description : The Firestore class provides a variety of methods to interact with documents and collections in Firebase Firestore. It allows you to filter, add, create, update, and delete documents in Firestore collections, including subcollections. For each method follow this structure:","title":"Firestore Documentation"},{"location":"api/firestore/#method-filtercollectionwithwhereclausecollection-filterkey-filterdata-operation","text":"Returns : An array of documents that match the provided filters. Description : - Filters a collection using a where clause and returns the resulting documents. - Throws an error if there is an issue retrieving the documents. Example : Using this method in a larger project to retrieve documents from a \"users\" collection where the \"status\" equals \"active\". const userDocs = await firestoreInstance.filterCollectionWithWhereClause( \"users\", \"status\", \"active\", \"==\" ); Parameters : Parameter Name Description Accepted Values/Data Types collection The name of the collection to be filtered. String filterKey The key/field name to filter by. String filterData The value to match for the given filterKey. String operation The Firestore query operator. String (Firestore query operators)","title":"Method: filterCollectionWithWhereClause(collection, filterKey, filterData, operation)"},{"location":"api/firestore/#method-adddocumenttocollectiondocument-collection","text":"Returns : An object containing the success status and the ID of the document added. Description : - Adds a new document to the specified collection. - If an error occurs, it throws an exception with the error details. Example : Adding a new user object to the \"users\" collection in Firestore. const addResult = await firestoreInstance.addDocumentToCollection(newUser, \"users\"); if (addResult.success) { console.log(`Added document with ID: ${addResult.docID}`); } Parameters : Parameter Name Description Accepted Values/Data Types document The data object of the document. Object collection The name of the target collection. String (Note: The documentation template above is applied to only the filterCollectionWithWhereClause method and addDocumentToCollection . Similar formatting would follow for each method defined within the Firestore class itself, but due to the length and number of methods, not all methods have been templated here. Each method should get its own section following the given structure.)","title":"Method: addDocumentToCollection(document, collection)"},{"location":"api/gdrive/","text":"# Gdrive Documentation **Description**: Gdrive is a JavaScript class designed for Node.js, intended to simplify interactions with Google Drive API. It allows developers to authenticate access, list directories and files, upload, update, and download files within Google Drive using Google's API. ### Method: `init(config)` **Returns**: An instance of the Gdrive class. **Description**: - Initializes a new instance of the Gdrive class using the provided configuration object. - Handles errors encountered during the initialization process. **Example**: How to initialize a Gdrive instance. ```javascript const Gdrive = require(\"./Gdrive\"); const config = { verbose: true, appType: 'server', client_id: 'your-client-id', client_secret: 'your-client-secret', redirect_uri: 'your-redirect-uri', scopes: 'https://www.googleapis.com/auth/drive', keyFilePath: 'path-to-keyfile.json' }; const driveInstance = await Gdrive.init(config); Parameters : Parameter Name Description Accepted Values/Data Types config An object containing the configuration for Object Gdrive initialization. Method: listFilez() Returns : Nothing directly, but logs the list of files to the console. Description : Lists up to 10 files from the authenticated user's Google Drive. Outputs the file names and IDs to the console. Handles errors and logs them to the console if listing fails. Example : List files in Google Drive. await driveInstance.listFilez(); Method: listFiles(props) Returns : An object with a status code, message, and data containing the list of files. Description : Retrieves a list of files from Google Drive based on various filter criteria such as directories, MIME type, and filename. Accepts a properties object to further customize the file listing. Handles exceptions and returns an error object if the operation fails. Example : Retrieve a specific list of files. const properties = { directory: 'Documents', mimeType: 'image/jpeg' }; const fileList = await driveInstance.listFiles(properties); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for listing Object the files, including directory, MIME type, and filename. Method: createFile(props) Returns : An object containing the status, message, and response data with the details of the created file. Description : Creates a file in Google Drive with specified properties including filename, MIME type, and contents. Accepts a properties object to customize the created file. Handles errors and returns an error object if the creation fails. Example : Create a new file in Google Drive. const fileProps = { filename: 'NewDocument.txt', mimeType: 'text/plain', message: 'Hello World' }; const createdFile = await driveInstance.createFile(fileProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for the file Object to be created, such as filename, MIME type, and content. Method: createAndOrGetContent(props) Returns : An object containing the status, message, and data with the details of the requested content or the content that was created. Description : Creates or retrieves the content specified by the path and MIME type from Google Drive. Recursively handles directory creation if not existing and retrieves or creates the final file or folder. Returns details of the content including metadata and file data. Handles error cases returning structured error responses. Example : Create or get content within a specified path. const contentProps = { path: '/MyDocuments/Project', mimeType: 'application/vnd.google-apps.folder' }; const content = await driveInstance.createAndOrGetContent(contentProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for the path, MIME Object type, and optional message content. Method: updateFile(props) Returns : An object containing the status, message, and response data with the details of the updated file. Description : Updates an existing file's content identified by the fileId in Google Drive. Accepts a properties object containing fileId, MIME type, and new contents for the file. Handles error cases and returns an error object if the update fails. Example : Update an existing file's content. const updateProps = { fileId: 'file-id', mimeType: 'text/plain', message: 'Updated Content' }; const updatedFile = await driveInstance.updateFile(updateProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing the fileId, MIME type, and Object new content for the file to be updated. Additional Static Methods: createOAuthServer : Creates and returns an Express server instance to facilitate OAuth authentication. getAuthUrl(config) : Creates and returns a Google OAuth URL based on provided parameters. handleAuthCallback(config) : Handles the OAuth callback to retrieve access tokens. checkAndRefresh(config) : Checks if an access token has expired and attempts to refresh it. refreshToken(config) : Refreshes the access token using the stored refresh token and returns the new access token. Static methods are invoked on the Gdrive class itself and not on instances of the class. They are commonly used for initial OAuth setup, token handling, and to check or refresh access tokens when needed. Navigate through our sections to find comprehensive guides and insights that suit your development needs! ```","title":"DriveUtils"},{"location":"api/gdrive/#method-listfilez","text":"Returns : Nothing directly, but logs the list of files to the console. Description : Lists up to 10 files from the authenticated user's Google Drive. Outputs the file names and IDs to the console. Handles errors and logs them to the console if listing fails. Example : List files in Google Drive. await driveInstance.listFilez();","title":"Method: listFilez()"},{"location":"api/gdrive/#method-listfilesprops","text":"Returns : An object with a status code, message, and data containing the list of files. Description : Retrieves a list of files from Google Drive based on various filter criteria such as directories, MIME type, and filename. Accepts a properties object to further customize the file listing. Handles exceptions and returns an error object if the operation fails. Example : Retrieve a specific list of files. const properties = { directory: 'Documents', mimeType: 'image/jpeg' }; const fileList = await driveInstance.listFiles(properties); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for listing Object the files, including directory, MIME type, and filename.","title":"Method: listFiles(props)"},{"location":"api/gdrive/#method-createfileprops","text":"Returns : An object containing the status, message, and response data with the details of the created file. Description : Creates a file in Google Drive with specified properties including filename, MIME type, and contents. Accepts a properties object to customize the created file. Handles errors and returns an error object if the creation fails. Example : Create a new file in Google Drive. const fileProps = { filename: 'NewDocument.txt', mimeType: 'text/plain', message: 'Hello World' }; const createdFile = await driveInstance.createFile(fileProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for the file Object to be created, such as filename, MIME type, and content.","title":"Method: createFile(props)"},{"location":"api/gdrive/#method-createandorgetcontentprops","text":"Returns : An object containing the status, message, and data with the details of the requested content or the content that was created. Description : Creates or retrieves the content specified by the path and MIME type from Google Drive. Recursively handles directory creation if not existing and retrieves or creates the final file or folder. Returns details of the content including metadata and file data. Handles error cases returning structured error responses. Example : Create or get content within a specified path. const contentProps = { path: '/MyDocuments/Project', mimeType: 'application/vnd.google-apps.folder' }; const content = await driveInstance.createAndOrGetContent(contentProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing properties for the path, MIME Object type, and optional message content.","title":"Method: createAndOrGetContent(props)"},{"location":"api/gdrive/#method-updatefileprops","text":"Returns : An object containing the status, message, and response data with the details of the updated file. Description : Updates an existing file's content identified by the fileId in Google Drive. Accepts a properties object containing fileId, MIME type, and new contents for the file. Handles error cases and returns an error object if the update fails. Example : Update an existing file's content. const updateProps = { fileId: 'file-id', mimeType: 'text/plain', message: 'Updated Content' }; const updatedFile = await driveInstance.updateFile(updateProps); Parameters : Parameter Name Description Accepted Values/Data Types props An object containing the fileId, MIME type, and Object new content for the file to be updated.","title":"Method: updateFile(props)"},{"location":"api/gdrive/#additional-static-methods","text":"createOAuthServer : Creates and returns an Express server instance to facilitate OAuth authentication. getAuthUrl(config) : Creates and returns a Google OAuth URL based on provided parameters. handleAuthCallback(config) : Handles the OAuth callback to retrieve access tokens. checkAndRefresh(config) : Checks if an access token has expired and attempts to refresh it. refreshToken(config) : Refreshes the access token using the stored refresh token and returns the new access token. Static methods are invoked on the Gdrive class itself and not on instances of the class. They are commonly used for initial OAuth setup, token handling, and to check or refresh access tokens when needed. Navigate through our sections to find comprehensive guides and insights that suit your development needs! ```","title":"Additional Static Methods:"},{"location":"api/heroku/","text":"# HerokuHandler Documentation **Description**: The `HerokuHandler` class is designed to facilitate interactions with the Heroku platform via its API. It provides methods to check if Heroku CLI is installed, verify login credentials, and handle Heroku specific tasks programmatically. ### Method: `constructor(props)` **Returns**: An instance of the `HerokuHandler` class. **Description**: - Initializes the `HerokuHandler` with the necessary properties to authenticate API requests. - Properties include Heroku API key, username, and password. **Example**: Create an instance of the `HerokuHandler` class. const herokuHandler = new HerokuHandler({ herokuApiKey: 'your-heroku-api-key', username: 'your-username', password: 'your-password' }); **Parameters**: | Parameter Name | Description | Accepted Values/Data Types | | -------------- | -------------------- | ----------------------------- | | props | Object containing authentication properties. | Object | ### Method: `checkInstall()` **Returns**: A promise that resolves to a boolean indicating if Heroku CLI is installed. **Description**: - Makes a GET request to the Heroku API to check if the Heroku CLI is installed. - Logs the CLI version if installed, otherwise logs an error. **Example**: Check if Heroku CLI is installed. herokuHandler.checkInstall() .then(isInstalled => { console.log(`Is Heroku installed: ${isInstalled}`); }); **Parameters**: None ### Method: `checkLogin()` **Returns**: A promise that resolves to a boolean indicating whether the user is logged in to Heroku. **Description**: - Makes a GET request to the Heroku API to verify if the user is logged in. - Logs the email address of the logged-in user if authentication is successful, otherwise logs an error. **Example**: Verify if the user is logged into Heroku. herokuHandler.checkLogin() .then(isLoggedIn => { console.log(`Is User logged in: ${isLoggedIn}`); }); **Parameters**: None ### Method: `handleHeroku(args)` **Returns**: A promise that resolves to an object containing the status and message of the Heroku login process. **Description**: - Static method that creates an instance of `HerokuHandler` and checks the installation and login status. - Returns an object that indicates whether the user is installed and/or logged in to Heroku. **Example**: Handle Heroku using provided arguments. HerokuHandler.handleHeroku({ herokuApiKey: 'your-heroku-api-key' }) .then(result => { console.log(result); }); **Parameters**: | Parameter Name | Description | Accepted Values/Data Types | | -------------- | -------------------- | -------------------------- | | args | Object containing properties to be passed to `HerokuHandler` constructor. | Object |","title":"Heroku"},{"location":"api/huggingFace/","text":"HuggingFace Documentation Description : The HuggingFace class serves as a wrapper for interacting with the Hugging Face APIs for operations such as model inference, repository creation, file management, and validity checks for API tokens and Hugging Face hubs. Method: tokenIsValid() Returns : A boolean indicating whether the provided API token is valid. Description : - This method checks the validity of the Hugging Face API token by attempting to list the available models. - If the token is valid, the method returns true , otherwise it returns false . - Catches and logs any errors during the validation process. Example : Verify the Hugging Face API token is valid before proceeding with further API interactions. const hf = new HuggingFace('your-token'); const isValid = await hf.tokenIsValid(); if (isValid) { console.log('Token is valid.'); } else { console.log('Invalid token, please check your credentials.'); } Parameters : None. Method: hubExists() Returns : A boolean indicating whether the target Hugging Face hub exists. Description : - This method verifies the existence of a Hugging Face hub by listing models. - If the hub exists, it returns true , otherwise it returns false . - Similar in functionality to tokenIsValid() and may be subject to change to better reflect its intended purpose. Example : Check if the Hugging Face hub exists. const hf = new HuggingFace('your-token'); const exists = await hf.hubExists(); if (exists) { console.log('Hub exists.'); } else { console.log('Hub does not exist.'); } Parameters : None. Method: questionAnswering(model, inputs) Returns : The method returns the result of a question answering model hosted on the Hugging Face platform. Description : - Calls upon a pre-trained question answering model, specified by the user, to process the provided inputs. Example : Use a question answering model to obtain answers based on provided input. const hf = new HuggingFace('your-token'); const model = \"bert-base-uncased\"; const inputs = { question: \"What is Hugging Face?\", context: \"Hugging Face is a social AI company and platform for ML models.\" }; const result = await hf.questionAnswering(model, inputs); console.log(result); Parameters : Parameter Name Description Accepted Values/Data Types model The identifier for the Hugging Face question answering model. String inputs The inputs containing the question and context for the model. Object { question, context } Method: createRepo(repoPath, type) Returns : The response from the Hugging Face API upon the creation of a new repository. Description : - Creates a new repository or a folder in the Hugging Face hub to store models or datasets. - Accepts a repository path and a type to specifically create a 'model' type repository if specified. Example : Create a new model repository at the specified path. const hf = new HuggingFace('your-token'); const repoPath = \"your-username/your-new-model\"; const repoType = \"model\"; const response = await hf.createRepo(repoPath, repoType); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types repoPath The path where the new repository will reside on the hub. String type The type of repository to create (optionally specify 'model'). String Method: uploadFile(repoPath, filePath, blob) Returns : The response from the Hugging Face API upon successful file upload. Description : - Uploads a file (e.g., a model file) to a specific repository on the Hugging Face hub. Example : Upload a model file to a specified repository. const hf = new HuggingFace('your-token'); const repoPath = \"your-username/your-model\"; const filePath = \"pytorch_model.bin\"; const blob = new Blob([...]); // blob containing file data const response = await hf.uploadFile(repoPath, filePath, blob); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types repoPath The repository path to upload the file to. String filePath The destination file path on the hub. String blob The file content to be uploaded. Blob Method: deleteFiles(type, name, paths) Returns : The response from the Hugging Face API after attempting to delete the specified files. Description : - Deletes one or more files within a repository or space on the Hugging Face hub. Example : Delete specific files in a model repository. const hf = new HuggingFace('your-token'); const type = \"model\"; const name = \"your-username/your-model\"; const paths = [\"file1.bin\", \"file2.bin\"]; const response = await hf.deleteFiles(type, name, paths); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types type The type of the target to delete files from. String name The path to the repo or space where the files are located. String paths An array of strings representing the file paths to delete. Array of String","title":"HuggingFace"},{"location":"api/huggingFace/#huggingface-documentation","text":"Description : The HuggingFace class serves as a wrapper for interacting with the Hugging Face APIs for operations such as model inference, repository creation, file management, and validity checks for API tokens and Hugging Face hubs.","title":"HuggingFace Documentation"},{"location":"api/huggingFace/#method-tokenisvalid","text":"Returns : A boolean indicating whether the provided API token is valid. Description : - This method checks the validity of the Hugging Face API token by attempting to list the available models. - If the token is valid, the method returns true , otherwise it returns false . - Catches and logs any errors during the validation process. Example : Verify the Hugging Face API token is valid before proceeding with further API interactions. const hf = new HuggingFace('your-token'); const isValid = await hf.tokenIsValid(); if (isValid) { console.log('Token is valid.'); } else { console.log('Invalid token, please check your credentials.'); } Parameters : None.","title":"Method: tokenIsValid()"},{"location":"api/huggingFace/#method-hubexists","text":"Returns : A boolean indicating whether the target Hugging Face hub exists. Description : - This method verifies the existence of a Hugging Face hub by listing models. - If the hub exists, it returns true , otherwise it returns false . - Similar in functionality to tokenIsValid() and may be subject to change to better reflect its intended purpose. Example : Check if the Hugging Face hub exists. const hf = new HuggingFace('your-token'); const exists = await hf.hubExists(); if (exists) { console.log('Hub exists.'); } else { console.log('Hub does not exist.'); } Parameters : None.","title":"Method: hubExists()"},{"location":"api/huggingFace/#method-questionansweringmodel-inputs","text":"Returns : The method returns the result of a question answering model hosted on the Hugging Face platform. Description : - Calls upon a pre-trained question answering model, specified by the user, to process the provided inputs. Example : Use a question answering model to obtain answers based on provided input. const hf = new HuggingFace('your-token'); const model = \"bert-base-uncased\"; const inputs = { question: \"What is Hugging Face?\", context: \"Hugging Face is a social AI company and platform for ML models.\" }; const result = await hf.questionAnswering(model, inputs); console.log(result); Parameters : Parameter Name Description Accepted Values/Data Types model The identifier for the Hugging Face question answering model. String inputs The inputs containing the question and context for the model. Object { question, context }","title":"Method: questionAnswering(model, inputs)"},{"location":"api/huggingFace/#method-createreporepopath-type","text":"Returns : The response from the Hugging Face API upon the creation of a new repository. Description : - Creates a new repository or a folder in the Hugging Face hub to store models or datasets. - Accepts a repository path and a type to specifically create a 'model' type repository if specified. Example : Create a new model repository at the specified path. const hf = new HuggingFace('your-token'); const repoPath = \"your-username/your-new-model\"; const repoType = \"model\"; const response = await hf.createRepo(repoPath, repoType); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types repoPath The path where the new repository will reside on the hub. String type The type of repository to create (optionally specify 'model'). String","title":"Method: createRepo(repoPath, type)"},{"location":"api/huggingFace/#method-uploadfilerepopath-filepath-blob","text":"Returns : The response from the Hugging Face API upon successful file upload. Description : - Uploads a file (e.g., a model file) to a specific repository on the Hugging Face hub. Example : Upload a model file to a specified repository. const hf = new HuggingFace('your-token'); const repoPath = \"your-username/your-model\"; const filePath = \"pytorch_model.bin\"; const blob = new Blob([...]); // blob containing file data const response = await hf.uploadFile(repoPath, filePath, blob); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types repoPath The repository path to upload the file to. String filePath The destination file path on the hub. String blob The file content to be uploaded. Blob","title":"Method: uploadFile(repoPath, filePath, blob)"},{"location":"api/huggingFace/#method-deletefilestype-name-paths","text":"Returns : The response from the Hugging Face API after attempting to delete the specified files. Description : - Deletes one or more files within a repository or space on the Hugging Face hub. Example : Delete specific files in a model repository. const hf = new HuggingFace('your-token'); const type = \"model\"; const name = \"your-username/your-model\"; const paths = [\"file1.bin\", \"file2.bin\"]; const response = await hf.deleteFiles(type, name, paths); console.log(response); Parameters : Parameter Name Description Accepted Values/Data Types type The type of the target to delete files from. String name The path to the repo or space where the files are located. String paths An array of strings representing the file paths to delete. Array of String","title":"Method: deleteFiles(type, name, paths)"},{"location":"api/huggingFace_og/","text":"HuggingFace The HuggingFace class in Node.js facilitates interaction with the Hugging Face API for operations such as validating tokens, managing repositories, uploading files, and performing model inference. Class: HuggingFace Constructor Parameters : accessToken (String): Access token for Hugging Face API. defaultOptions (Object): Default options for the class. Description : Initializes the class with the provided access token and default options. Sets up an instance of HfInference for model inference tasks. Method: tokenIsValid() Returns : Boolean indicating if the token is valid. Description : Validates the provided access token by attempting to list models. Logs the process and errors if any. Method: hubExists() Returns : Boolean indicating if the hub exists. Description : Checks for the existence of a hub by attempting to list models. Handles and logs any errors encountered. Method: questionAnswering(model, inputs) Parameters : model (String): The model to use for question answering. inputs (String): The inputs for the model. Returns : The result of the question answering model. Description : Calls a question-answering model on the Hugging Face platform. Returns the model's response. Method: createRepo(repoPath, type) Parameters : repoPath (String): The path to the repository. type (String): The type of repository. Returns : Result of repository creation. Description : Creates a repository or folder in the Hugging Face hub. Handles different repository types. Method: uploadFile(repoPath, filePath, blob) Parameters : repoPath (String): The repository path. filePath (String): The file path. blob (Blob): The file content. Returns : Result of file upload. Description : Uploads a file to the specified repository in the Hugging Face hub. Method: deleteFiles(type, name, paths) Parameters : type (String): Type of repository or space. name (String): The path to the repo or space. paths (Array): File paths to delete. Returns : Result of file deletion. Description : Deletes files in the specified repository or space on the Hugging Face hub. Export The HuggingFace class is exported for use in other modules. Comments and TODOs The code includes TODO comments outlining future goals like updating models, connecting models to inference endpoints, checking for space existence, and managing space resources. These comments link to relevant documentation for further guidance on these tasks.","title":"HuggingFace"},{"location":"api/huggingFace_og/#huggingface","text":"The HuggingFace class in Node.js facilitates interaction with the Hugging Face API for operations such as validating tokens, managing repositories, uploading files, and performing model inference.","title":"HuggingFace"},{"location":"api/huggingFace_og/#class-huggingface","text":"","title":"Class: HuggingFace"},{"location":"api/huggingFace_og/#constructor","text":"Parameters : accessToken (String): Access token for Hugging Face API. defaultOptions (Object): Default options for the class. Description : Initializes the class with the provided access token and default options. Sets up an instance of HfInference for model inference tasks.","title":"Constructor"},{"location":"api/huggingFace_og/#method-tokenisvalid","text":"Returns : Boolean indicating if the token is valid. Description : Validates the provided access token by attempting to list models. Logs the process and errors if any.","title":"Method: tokenIsValid()"},{"location":"api/huggingFace_og/#method-hubexists","text":"Returns : Boolean indicating if the hub exists. Description : Checks for the existence of a hub by attempting to list models. Handles and logs any errors encountered.","title":"Method: hubExists()"},{"location":"api/huggingFace_og/#method-questionansweringmodel-inputs","text":"Parameters : model (String): The model to use for question answering. inputs (String): The inputs for the model. Returns : The result of the question answering model. Description : Calls a question-answering model on the Hugging Face platform. Returns the model's response.","title":"Method: questionAnswering(model, inputs)"},{"location":"api/huggingFace_og/#method-createreporepopath-type","text":"Parameters : repoPath (String): The path to the repository. type (String): The type of repository. Returns : Result of repository creation. Description : Creates a repository or folder in the Hugging Face hub. Handles different repository types.","title":"Method: createRepo(repoPath, type)"},{"location":"api/huggingFace_og/#method-uploadfilerepopath-filepath-blob","text":"Parameters : repoPath (String): The repository path. filePath (String): The file path. blob (Blob): The file content. Returns : Result of file upload. Description : Uploads a file to the specified repository in the Hugging Face hub.","title":"Method: uploadFile(repoPath, filePath, blob)"},{"location":"api/huggingFace_og/#method-deletefilestype-name-paths","text":"Parameters : type (String): Type of repository or space. name (String): The path to the repo or space. paths (Array): File paths to delete. Returns : Result of file deletion. Description : Deletes files in the specified repository or space on the Hugging Face hub.","title":"Method: deleteFiles(type, name, paths)"},{"location":"api/huggingFace_og/#export","text":"The HuggingFace class is exported for use in other modules.","title":"Export"},{"location":"api/huggingFace_og/#comments-and-todos","text":"The code includes TODO comments outlining future goals like updating models, connecting models to inference endpoints, checking for space existence, and managing space resources. These comments link to relevant documentation for further guidance on these tasks.","title":"Comments and TODOs"},{"location":"api/llmOverview/","text":"LLM Overview Welcome to the LLM Overview! Here, we delve into the intricacies and unique features of several Node.js classes. Our goal is to offer you an engaging and informative guide through their functionalities and capabilities, making your development journey both efficient and enjoyable. HuggingFace Class Overview Class: HuggingFace The HuggingFace class is your gateway to interacting with the innovative Hugging Face API. From validating tokens and managing repositories to uploading files and performing model inference, this class is equipped to handle it all with ease. Constructor Parameters : accessToken (String): Your key to access the diverse features of the Hugging Face API. defaultOptions (Object): Customize the class behavior to suit your needs. Key Methods tokenIsValid() : Wondering about your token's validity? This method swiftly confirms it for you. hubExists() : Check if your desired hub is up and running with a simple call. questionAnswering(model, inputs) : Dive into AI-driven question answering with your chosen model. createRepo(repoPath, type) : Setting up a new repository is just a few parameters away. uploadFile(repoPath, filePath, blob) : Easily upload files to your repository in the Hugging Face hub. deleteFiles(type, name, paths) : Need to clear some space? Delete files seamlessly with this method. HerokuHandler Class Overview Class: HerokuHandler Embark on a smooth journey with Heroku using the HerokuHandler class. It simplifies interactions with the Heroku API, ensuring you can check installation and login statuses effortlessly. Constructor Parameters : props (Object): All you need to connect - Heroku API key, username, and password. Key Methods checkInstall() : Quickly verify if Heroku CLI is part of your toolkit. checkLogin() : Log in hassles? This method ensures you're connected to Heroku. handleHeroku(args) : Manage your Heroku setup and status with this comprehensive function. NPM: Langdrive: DriveChatbot Class Overview Chatbot Primarily for demonstration and testing purposes. Engage with the DriveChatbot , where Async Promises bring your chatbot interactions to life. Train Class Overview Class: Train The Train class is your companion in the realm of machine learning. It's designed to streamline the training process of your models and manage data sources efficiently. Constructor Parameters : props (Object): Fine-tune your training experience with verbose and train options. Key Methods init(config) : Initializes the class and prepares data. trainModel(huggingfaceInfo) : Manages the model training process. prepareData() : Prepares training data. getDataFromUrl(url) : Fetches data from a URL. getDataFromService(classInstance, query) : Retrieves data using a service class. getValuesFromData(data, value) : Extracts specific values from data. getData(lbl) : General method for data retrieval. Utils Script Overview Script: utils This Node.js script is essential for deploying machine learning models. It utilizes key libraries like fs , path , js-yaml , and dotenv for various file operations, path resolution, YAML processing, and environment variable management. Main Functions cli_deploy(args) : Entry point for deploying the model. Manages deployment initiation and configuration retrieval. deploy(config) : Handles the core deployment process of the machine learning model. getConfig(args) : Retrieves deployment configurations from a YAML file. Modules fs : Handles file system operations. path : Manages file paths. js-yaml : Processes YAML files. dotenv : Loads environment variables.","title":"Overview"},{"location":"api/llmOverview/#llm-overview","text":"Welcome to the LLM Overview! Here, we delve into the intricacies and unique features of several Node.js classes. Our goal is to offer you an engaging and informative guide through their functionalities and capabilities, making your development journey both efficient and enjoyable.","title":"LLM Overview"},{"location":"api/llmOverview/#huggingface-class-overview","text":"","title":"HuggingFace Class Overview"},{"location":"api/llmOverview/#class-huggingface","text":"The HuggingFace class is your gateway to interacting with the innovative Hugging Face API. From validating tokens and managing repositories to uploading files and performing model inference, this class is equipped to handle it all with ease.","title":"Class: HuggingFace"},{"location":"api/llmOverview/#constructor","text":"Parameters : accessToken (String): Your key to access the diverse features of the Hugging Face API. defaultOptions (Object): Customize the class behavior to suit your needs.","title":"Constructor"},{"location":"api/llmOverview/#key-methods","text":"tokenIsValid() : Wondering about your token's validity? This method swiftly confirms it for you. hubExists() : Check if your desired hub is up and running with a simple call. questionAnswering(model, inputs) : Dive into AI-driven question answering with your chosen model. createRepo(repoPath, type) : Setting up a new repository is just a few parameters away. uploadFile(repoPath, filePath, blob) : Easily upload files to your repository in the Hugging Face hub. deleteFiles(type, name, paths) : Need to clear some space? Delete files seamlessly with this method.","title":"Key Methods"},{"location":"api/llmOverview/#herokuhandler-class-overview","text":"","title":"HerokuHandler Class Overview"},{"location":"api/llmOverview/#class-herokuhandler","text":"Embark on a smooth journey with Heroku using the HerokuHandler class. It simplifies interactions with the Heroku API, ensuring you can check installation and login statuses effortlessly.","title":"Class: HerokuHandler"},{"location":"api/llmOverview/#constructor_1","text":"Parameters : props (Object): All you need to connect - Heroku API key, username, and password.","title":"Constructor"},{"location":"api/llmOverview/#key-methods_1","text":"checkInstall() : Quickly verify if Heroku CLI is part of your toolkit. checkLogin() : Log in hassles? This method ensures you're connected to Heroku. handleHeroku(args) : Manage your Heroku setup and status with this comprehensive function.","title":"Key Methods"},{"location":"api/llmOverview/#npm-langdrive-drivechatbot-class-overview","text":"","title":"NPM: Langdrive: DriveChatbot Class Overview"},{"location":"api/llmOverview/#chatbot","text":"Primarily for demonstration and testing purposes. Engage with the DriveChatbot , where Async Promises bring your chatbot interactions to life.","title":"Chatbot"},{"location":"api/llmOverview/#train-class-overview","text":"","title":"Train Class Overview"},{"location":"api/llmOverview/#class-train","text":"The Train class is your companion in the realm of machine learning. It's designed to streamline the training process of your models and manage data sources efficiently.","title":"Class: Train"},{"location":"api/llmOverview/#constructor_2","text":"Parameters : props (Object): Fine-tune your training experience with verbose and train options.","title":"Constructor"},{"location":"api/llmOverview/#key-methods_2","text":"init(config) : Initializes the class and prepares data. trainModel(huggingfaceInfo) : Manages the model training process. prepareData() : Prepares training data. getDataFromUrl(url) : Fetches data from a URL. getDataFromService(classInstance, query) : Retrieves data using a service class. getValuesFromData(data, value) : Extracts specific values from data. getData(lbl) : General method for data retrieval.","title":"Key Methods"},{"location":"api/llmOverview/#utils-script-overview","text":"","title":"Utils Script Overview"},{"location":"api/llmOverview/#script-utils","text":"This Node.js script is essential for deploying machine learning models. It utilizes key libraries like fs , path , js-yaml , and dotenv for various file operations, path resolution, YAML processing, and environment variable management.","title":"Script: utils"},{"location":"api/llmOverview/#main-functions","text":"cli_deploy(args) : Entry point for deploying the model. Manages deployment initiation and configuration retrieval. deploy(config) : Handles the core deployment process of the machine learning model. getConfig(args) : Retrieves deployment configurations from a YAML file.","title":"Main Functions"},{"location":"api/llmOverview/#modules","text":"fs : Handles file system operations. path : Manages file paths. js-yaml : Processes YAML files. dotenv : Loads environment variables.","title":"Modules"},{"location":"api/overview/","text":"quickstart Should explain the YAML attributes in detail. or have a quick start YAML template. Pass a CSV URL as a data connector of input and output. Put sample CSVs to test Be a page on Docusaurus Document the data connectors and how they work with YAML attributes https://docs.litellm.ai/docs/completion For now: It\u2019s just Firestore, Email, and GDrive Deploy to docusaurus Document deployment options and push to docusaurus HuggingFace and their respective YAML config attributes deploy to huggingace attribute, Document Models Available and how it connects to the YAML config Falcon-7b-sharded And how to configure it in the YAML","title":"Overview"},{"location":"api/train/","text":"# Train Documentation **Description**: The `Train` class is designed for training language models using various data sources, including CSV files, service responses, and structured data. It handles the preparation of training data and interacts with a training API to finetune models on the Hugging Face platform. ### Method: `init(config)` **Returns**: An instance of the `Train` class after it has been initialized with the provided configuration. **Description**: - This static method initializes the `Train` class with the given configuration object. - It returns a new instance of the class once it has prepared the necessary training data. - It prints the 'DriveTrain init()' message if the verbose option is set to true. **Example**: To initialize a `Train` instance using a configuration object. ```javascript const config = { verbose: true, /*...otherProps*/ }; const trainInstance = await Train.init(config); Parameters : Parameter Name Description Accepted Values/Data Types config An object containing configuration properties for the class instance. Object Method: trainModel(huggingfaceInfo) Returns : A promise that resolves with the model training response. Description : - Trains a model with the prepared data and Hugging Face API information. - Communicates with a training server API to initiate the finetuning process. - Handles verbose logs if enabled. Example : To train a model with the prepared data and provided Hugging Face information. const huggingfaceInfo = { baseModel: 'model-name', hfToken: 'your-huggingface-token', deployToHf: true, trainedModel: 'username/finetuned-model-name' }; const trainingResponse = await trainInstance.trainModel(huggingfaceInfo); Parameters : Parameter Name Description Accepted Values/Data Types huggingfaceInfo An object containing information required for the Hugging Face API. Object Method: prepareData() Returns : A promise that resolves with an array of training data objects. Description : - Prepares training data by retrieving input and output data from various sources. - Maps input data to corresponding output data to form training pairs. - Logs the preparation process if verbose mode is enabled. Example : To prepare the training data internally within the instance. const trainingData = await trainInstance.prepareData(); Parameters : This method does not require external parameters as it utilizes the instance properties. Method: getData(lbl) Returns : A promise that resolves with the data retrieved from the specified label (input or output). Description : - Retrieves data based on the label, which indicates whether it's input or output data. - Manages retrieval from a URL, service, or directly from provided data. - Can log the process if verbose option is set to true. Example : To get data from the specified label within the class instance. const inputData = await trainInstance.getData('input'); Parameters : Parameter Name Description Accepted Values/Data Types lbl A label indicating what data to retrieve ('input' or 'output'). String ```","title":"Train"},{"location":"api/train/#method-trainmodelhuggingfaceinfo","text":"Returns : A promise that resolves with the model training response. Description : - Trains a model with the prepared data and Hugging Face API information. - Communicates with a training server API to initiate the finetuning process. - Handles verbose logs if enabled. Example : To train a model with the prepared data and provided Hugging Face information. const huggingfaceInfo = { baseModel: 'model-name', hfToken: 'your-huggingface-token', deployToHf: true, trainedModel: 'username/finetuned-model-name' }; const trainingResponse = await trainInstance.trainModel(huggingfaceInfo); Parameters : Parameter Name Description Accepted Values/Data Types huggingfaceInfo An object containing information required for the Hugging Face API. Object","title":"Method: trainModel(huggingfaceInfo)"},{"location":"api/train/#method-preparedata","text":"Returns : A promise that resolves with an array of training data objects. Description : - Prepares training data by retrieving input and output data from various sources. - Maps input data to corresponding output data to form training pairs. - Logs the preparation process if verbose mode is enabled. Example : To prepare the training data internally within the instance. const trainingData = await trainInstance.prepareData(); Parameters : This method does not require external parameters as it utilizes the instance properties.","title":"Method: prepareData()"},{"location":"api/train/#method-getdatalbl","text":"Returns : A promise that resolves with the data retrieved from the specified label (input or output). Description : - Retrieves data based on the label, which indicates whether it's input or output data. - Manages retrieval from a URL, service, or directly from provided data. - Can log the process if verbose option is set to true. Example : To get data from the specified label within the class instance. const inputData = await trainInstance.getData('input'); Parameters : Parameter Name Description Accepted Values/Data Types lbl A label indicating what data to retrieve ('input' or 'output'). String ```","title":"Method: getData(lbl)"},{"location":"api/utils/","text":"utils This documentation outlines the functionality of a Node.js script designed for deploying a machine learning model. Key libraries such as fs , path , js-yaml , and dotenv are used for file system operations, path resolution, YAML processing, and environment variable configuration, respectively. Modules fs : Node.js File System module for handling file operations. path : Node.js Path module for handling file paths. js-yaml : JavaScript library for YAML processing. dotenv : Module for loading environment variables from a .env file. Custom Modules Train : A custom module that likely handles the training of a machine learning model. Main Functions cli_deploy(args) Purpose : Entry point for deploying the model. Prints start log and initiates the deployment process. Parameters : args - Arguments passed from the command line. Process : Logs the initiation of deployment. Retrieves configuration from getConfig function. Calls deploy function with the retrieved configuration. deploy(config) Purpose : Manages the deployment of the machine learning model. Parameters : config - Configuration object for deployment. Process : Logs the start of deployment. Initializes class instances for various services defined in config . Trains the model using the Train module. Handles additional deployment steps (commented out in the provided code). getConfig(args) Purpose : Retrieves configuration settings from a YAML file. Parameters : args - Arguments passed from the command line. Process : Determines the YAML file path based on the provided arguments. Reads and parses the YAML file using js-yaml . Replaces placeholders with environment variable values. Returns the parsed and processed configuration object. Exported Modules The script exports the deploy , getConfig , and cli_deploy functions for external usage. Comments There are commented-out sections in the deploy and getConfig functions which hint at additional functionalities related to services like Heroku and Firebase. The script uses environment variables extensively, indicating a dynamic configuration setup.","title":"utils"},{"location":"api/utils/#utils","text":"This documentation outlines the functionality of a Node.js script designed for deploying a machine learning model. Key libraries such as fs , path , js-yaml , and dotenv are used for file system operations, path resolution, YAML processing, and environment variable configuration, respectively.","title":"utils"},{"location":"api/utils/#modules","text":"fs : Node.js File System module for handling file operations. path : Node.js Path module for handling file paths. js-yaml : JavaScript library for YAML processing. dotenv : Module for loading environment variables from a .env file.","title":"Modules"},{"location":"api/utils/#custom-modules","text":"Train : A custom module that likely handles the training of a machine learning model.","title":"Custom Modules"},{"location":"api/utils/#main-functions","text":"","title":"Main Functions"},{"location":"api/utils/#cli_deployargs","text":"Purpose : Entry point for deploying the model. Prints start log and initiates the deployment process. Parameters : args - Arguments passed from the command line. Process : Logs the initiation of deployment. Retrieves configuration from getConfig function. Calls deploy function with the retrieved configuration.","title":"cli_deploy(args)"},{"location":"api/utils/#deployconfig","text":"Purpose : Manages the deployment of the machine learning model. Parameters : config - Configuration object for deployment. Process : Logs the start of deployment. Initializes class instances for various services defined in config . Trains the model using the Train module. Handles additional deployment steps (commented out in the provided code).","title":"deploy(config)"},{"location":"api/utils/#getconfigargs","text":"Purpose : Retrieves configuration settings from a YAML file. Parameters : args - Arguments passed from the command line. Process : Determines the YAML file path based on the provided arguments. Reads and parses the YAML file using js-yaml . Replaces placeholders with environment variable values. Returns the parsed and processed configuration object.","title":"getConfig(args)"},{"location":"api/utils/#exported-modules","text":"The script exports the deploy , getConfig , and cli_deploy functions for external usage.","title":"Exported Modules"},{"location":"api/utils/#comments","text":"There are commented-out sections in the deploy and getConfig functions which hint at additional functionalities related to services like Heroku and Firebase. The script uses environment variables extensively, indicating a dynamic configuration setup.","title":"Comments"},{"location":"security/authentication/","text":"App Authentication In order to connect to googleDrive you will need proper google app credentials. You can follow these directions to help you get started. Visit this page: https://console.cloud.google.com/apis/credentials You can find it from the google cloud console homepage by clicking \"api's and services\", then clicking \"credentials\" from the tabbed navigation on the left-side of the page that loads. Once on the page, click 'create credentials' -> 'oAuth Client Id'. On the resulting page you will have to select what kind of credentials these are. You may need to visit this page twice because: If you want langDrive to access company resources through a private and secure server. - Select 'desktop app' as your 'app' type If you want user authentication and googleDrive access using langDrive - Select 'Web application' - You will be asked to provide valid js origins from which the oAuth process will occur. Common Options: http://localhost:3000 http://localhost:3000/chat http://localhost:3000/auth http://localhost:3000/auth/callback Once your app is created, a popup will give your a 'desktop app' id and secret, and also an option to 'download json'. Either store the id, secret in your .env file, or provide a path to the jsonString, or even convert the json to a string and use that. you need to point to the drive server file. be sure to rename it because the file comes in funny","title":"App Authentication"},{"location":"security/authentication/#app-authentication","text":"In order to connect to googleDrive you will need proper google app credentials. You can follow these directions to help you get started. Visit this page: https://console.cloud.google.com/apis/credentials You can find it from the google cloud console homepage by clicking \"api's and services\", then clicking \"credentials\" from the tabbed navigation on the left-side of the page that loads. Once on the page, click 'create credentials' -> 'oAuth Client Id'. On the resulting page you will have to select what kind of credentials these are. You may need to visit this page twice because: If you want langDrive to access company resources through a private and secure server. - Select 'desktop app' as your 'app' type If you want user authentication and googleDrive access using langDrive - Select 'Web application' - You will be asked to provide valid js origins from which the oAuth process will occur. Common Options: http://localhost:3000 http://localhost:3000/chat http://localhost:3000/auth http://localhost:3000/auth/callback Once your app is created, a popup will give your a 'desktop app' id and secret, and also an option to 'download json'. Either store the id, secret in your .env file, or provide a path to the jsonString, or even convert the json to a string and use that. you need to point to the drive server file. be sure to rename it because the file comes in funny","title":"App Authentication"},{"location":"security/verification/","text":"App Verification In order to deploy an app that connects to googleDrive, you will typically need higher degrees of app verification. You can follow these directions to help you get started. https://support.google.com/cloud/answer/9110914 If your app requests scopes categorized as sensitive or restricted, you will probably need to complete the verification process (see, however, the exceptions). Depending on the degree of access you need \u2014 read-only, read and write, and so on. Restricted scopes are fewer in number, currently including only scopes used by the Gmail APIs, Drive APIs, and Google Fit APIs. https://developers.google.com/identity/protocols/oauth2/scopes#drive - https://www.googleapis.com/auth/drive - https://www.googleapis.com/auth/drive.readonly - https://www.googleapis.com/auth/drive.activity - https://www.googleapis.com/auth/drive.activity.readonly - https://www.googleapis.com/auth/drive.metadata - https://www.googleapis.com/auth/drive.metadata.readonly - https://www.googleapis.com/auth/drive.scripts If your app requests any of the following scopes, and doesn't meet any of the criteria for an exception (see below), you will need to satisfy both the API Services User Data Policy, the Additional Requirements for Specific Scopes, which may require a more extensive review process. Unverified Apps https://support.google.com/cloud/answer/7454865?hl=en Verification for apps 1. Before you start the verification process, review the OAuth Application Verification FAQ. This will help your verification process go quickly. To start the verification process for apps, do the following steps: Update the OAuth consent screen details in the Google Cloud Platform Console APIs & Services Credentials: You must have a privacy policy URL. Add URLs for your homepage and Terms of Service if you have them. Verify your website ownership through Search Console To start the verification process, submit a verification request by using the following process. a. On the GCP Console OAuth consent screen, click Submit or Save. i. https://console.cloud.google.com/apis/credentials/consent?sjid=413868014423275458-NA b. If a verification required dialog displays: i. Add information in the text boxes for Google to verify your OAuth consent screen. ii. When you're finished entering details, click Submit. Note: If you add any new redirect URLs or JavaScript origins, or if you change your product name after verification, you have to go through verification again. https://developers.google.com/terms/api-services-user-data-policy https://developers.google.com/terms/api-services-user-data-policy#additional_requirements_for_specific_api_scopes https://developers.google.com/terms/ https://developers.google.com/identity/branding-guidelines - if using scopes","title":"App Verification"},{"location":"security/verification/#app-verification","text":"In order to deploy an app that connects to googleDrive, you will typically need higher degrees of app verification. You can follow these directions to help you get started. https://support.google.com/cloud/answer/9110914 If your app requests scopes categorized as sensitive or restricted, you will probably need to complete the verification process (see, however, the exceptions). Depending on the degree of access you need \u2014 read-only, read and write, and so on. Restricted scopes are fewer in number, currently including only scopes used by the Gmail APIs, Drive APIs, and Google Fit APIs. https://developers.google.com/identity/protocols/oauth2/scopes#drive - https://www.googleapis.com/auth/drive - https://www.googleapis.com/auth/drive.readonly - https://www.googleapis.com/auth/drive.activity - https://www.googleapis.com/auth/drive.activity.readonly - https://www.googleapis.com/auth/drive.metadata - https://www.googleapis.com/auth/drive.metadata.readonly - https://www.googleapis.com/auth/drive.scripts If your app requests any of the following scopes, and doesn't meet any of the criteria for an exception (see below), you will need to satisfy both the API Services User Data Policy, the Additional Requirements for Specific Scopes, which may require a more extensive review process. Unverified Apps https://support.google.com/cloud/answer/7454865?hl=en Verification for apps 1. Before you start the verification process, review the OAuth Application Verification FAQ. This will help your verification process go quickly. To start the verification process for apps, do the following steps: Update the OAuth consent screen details in the Google Cloud Platform Console APIs & Services Credentials: You must have a privacy policy URL. Add URLs for your homepage and Terms of Service if you have them. Verify your website ownership through Search Console To start the verification process, submit a verification request by using the following process. a. On the GCP Console OAuth consent screen, click Submit or Save. i. https://console.cloud.google.com/apis/credentials/consent?sjid=413868014423275458-NA b. If a verification required dialog displays: i. Add information in the text boxes for Google to verify your OAuth consent screen. ii. When you're finished entering details, click Submit. Note: If you add any new redirect URLs or JavaScript origins, or if you change your product name after verification, you have to go through verification again. https://developers.google.com/terms/api-services-user-data-policy https://developers.google.com/terms/api-services-user-data-policy#additional_requirements_for_specific_api_scopes https://developers.google.com/terms/ https://developers.google.com/identity/branding-guidelines - if using scopes","title":"App Verification"}]}